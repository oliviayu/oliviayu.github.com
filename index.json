[{"authors":null,"categories":null,"content":"I completed my PhD program in Statistics in 2018 winter, under the supervision of Prof. Lang Wu in the Department of Statistics  at the University of British Columbia (UBC).\nI finished my Master\u0026rsquo;s program in Statistics at UBC in 2013. In 2011, I received my Bachelor\u0026rsquo;s degree in Statistics from Zhejiang University of Finance and Economics in China. .\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/admin/","section":"author","summary":"I completed my PhD program in Statistics in 2018 winter, under the supervision of Prof. Lang Wu in the Department of Statistics  at the University of British Columbia (UBC).\nI finished my Master\u0026rsquo;s program in Statistics at UBC in 2013. In 2011, I received my Bachelor\u0026rsquo;s degree in Statistics from Zhejiang University of Finance and Economics in China. .","tags":null,"title":"Tingting Yu","type":"author"},{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536444000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536444000,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/tutorial/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f4d7d8e2a0129bf0277ebe9bf2ca8cce","permalink":"/about/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/about/","section":"about","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f38631c06dc52d51e25323771c266097","permalink":"/post/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1a618c6ad5e840d40b2ef44df562adec","permalink":"/author/skills/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/skills/","section":"author","summary":"","tags":null,"title":null,"type":"author"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aa2f8256064e29f2b3aec489c007f79a","permalink":"/experience/experience/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/experience/experience/","section":"experience","summary":"","tags":null,"title":"Experience","type":"experience"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"96dd649331fb96742c48729fc7815814","permalink":"/recent_posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/recent_posts/","section":"","summary":"","tags":null,"title":"Recent Posts","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7ecdd4a6de39fb3c3d4ff43482669f6a","permalink":"/project/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/projects/","section":"project","summary":"","tags":null,"title":"Projects","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"523e67a9409657937fe78a2f6d2cbdfc","permalink":"/talk/talks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/talks/","section":"talk","summary":"","tags":null,"title":"Recent \u0026 Upcoming Talks","type":"talk"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"20fbb49702cd08433cf33f5cad553745","permalink":"/author/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/contact/","section":"author","summary":"","tags":null,"title":null,"type":"author"},{"authors":null,"categories":["programming"],"content":" Configuration Set up global configuration variables if you haven\u0026rsquo;t done so\n$ git config --global user.name \u0026quot;\u0026lt;name\u0026gt;\u0026quot; $ git config --global user.email \u0026quot;\u0026lt;email\u0026gt;\u0026quot;  Git should automatically do a rebase when you do a pull, which is what you want\n$ git config branch.autosetuprebase always  To set up configuration for DiffMerge, follow the guide http://coding4streetcred.com/blog/post/configure-diffmerge-for-your-git-difftool.\nLocal Usage of Git Staging Check if there is any unstaged or untracked files\n$ git status  Add files to the staging\n$ git add \u0026lt;file.name\u0026gt; // add a specific file $ git add . // add all files from the current folder $ git add myfolder/ // add all files from the subfolder 'myfolder' $ git add (-A) // add all files from entire working tree, even from upper directory $ git add --no-all myfolder/ // add all but deleted files from myfolder: `` $ git add -u or --update // add all but new or untracked files  Remove files from the staging\n$ git reset HEAD \u0026lt;file.name\u0026gt; // remove a specific file $ git reset // remove everything from the staging area  Reset\n$ git checkout -- \u0026lt;filename\u0026gt; // discard the changes in a file $ git reset --soft HEAD~1 // leave all your changed files \u0026quot;Changes to be committed\u0026quot;, as git status would put it $ git reset --soft \u0026lt;commit hash\u0026gt; // move back to staging dir and keep the modification $ git reset \u0026lt;commit hash\u0026gt; // move back to working dir and keep the modification $ git reset --hard \u0026lt;commit hash\u0026gt; // revert tracked files back before modification  $ git clean -df // get rid of any untracked dir and files $ git reflog // lifesaver if you accidently delete something important $ git revert \u0026lt;hash\u0026gt; // ?  Commit Commit changes\n$ git commit -m \u0026quot;\u0026lt;messages\u0026gt;\u0026quot; // commit with a message created $ git commit --amend -m \u0026quot;\u0026lt;new messages\u0026gt;\u0026quot; // edit the commit message $ git commit --amend // commit changes to the previous commit  Show commit history\n$ git log  How to write a great Git commit message  Separate subject from body with a blank line Limit the subject line to 50 characters Capitalize the subject line Do not end the subject line with a period Use the imperative mood in the subject line Wrap the body at 72 characters Use the body to explain what and why vs. how  Edit a specific commit $ git rebase -i @~3 # Show the last 3 commits in a text editor  Find the commit you want, change pick to e (edit), and save and close the file. Git will rewind to that commit, allowing you to either:\n use $ git commit --amend to make changes, or\n use $ git reset @~ to discard the last commit, but not the changes to the files (i.e. take you to the point you were at when you\u0026rsquo;d edited the files, but hadn\u0026rsquo;t committed yet).\n  Then run $ git rebase --continue and Git will replay the subsequent changes on top of your modified commit. You may be asked to fix some merge conflicts. Note: @ is shorthand for HEAD, and ~ is the commit before the specified commit.\nOther approaches: https://stackoverflow.com/questions/1186535/how-to-modify-a-specified-commit-in-git\nSquash several commits into one Step 1: Invoke git to start an interactive rebase session:\n$ git rebase -i HEAD~[N]\nwhere N is the number of commits you want to join, starting from the most resent one. For example $ git rebase -i HEAD~3.\nOR if you have too many commits to count, try\n$ git rebase -i [commit-hash]\nwhere [commit-hash] is the hash of the commit just before the first one you want to rewrite from. For example, $ git rebase -i 5392bc to join the top 3 commits in below\nfdascc Fix at 13:00 asfdsd Fix at 12:00 kgfdas Fix at 11:00 5392bc Fix at 10:00  Step 2: Picking and squashing\nAt this point your editor of choice will pop up, showing the list of commits you want to merge in a reverse order. For example,\npick kgfdas Fix at 11:00 pick asfdsd Fix at 12:00 pick fdascc Fix at 13:00  Our task here is to mark all the commits as squashable, except the first/older one: it will be used as a starting point. You mark a commit as squashable by changing the work pick into squash next to it (or s for brevity, as stated in the comments). The result would be:\npick kgfdas Fix at 11:00 s asfdsd Fix at 12:00 s fdascc Fix at 13:00  Save the file and close the editor.\nStep 3: Create the new commit\nYou have just told Git to combine all three commits into the the first commit in the list. It\u0026rsquo;s now time to give it a name: your editor pops up again with a default message, made of the names of all the commits you have squashed.\nYou can leave it as it is and the commit message will result in a list of all the intermediate commits, or wipe out the default message and use something more self-explanatory.\nBranch You can edit and commit under a branch which wont affect the master branch at all\n$ git branch // check which branch you are currently in (with *) $ git branch \u0026lt;branch_name\u0026gt; // create a branch $ git checkout \u0026lt;branch_name\u0026gt; // switch to the selected branch  $ git cherry-pick \u0026lt;commit hash\u0026gt; # bring the commit to the current branch  Merge Branch\n$ git checkout master $ git merge \u0026lt;branch_name\u0026gt; $ git branch --merged // check if it's merged successfully  Delete a branch\n$ git branch -d \u0026lt;branch_name\u0026gt; // delete branch locally $ git push origin --delete \u0026lt;branch_name\u0026gt; // delete branch remotely  Stash You can save changes in a temporary place so you can work on other things and come back later. Note that stash won\u0026rsquo;t create anything to commit.\n$ git stash save \u0026quot;\u0026lt;message\u0026gt;\u0026quot; // save changes in stash $ git stash list // check existing stash $ git stash apply \u0026lt;stash name\u0026gt; // fetch the changes in the stash $ git stash pop // apply changes in the top stash (the newest) and drop it from the stash list $ git stash drop \u0026lt;stash name\u0026gt; // drop the selected stash $ git stash clear // remove all the changes made  Visual Tool DiffMerge\n$ git difftool $ git mergetool  Gitk\n$ gitk  Others Check changes made in the code:\n$ git diff \u0026lt;old hash\u0026gt; \u0026lt;new hash\u0026gt;  Create an ignore file:\n$ touch .gitignore  The .gitignore file is a text file that list the files you want to ignore for tracking.\nRemote Usage of Git Clone a project:\n$ git clone \u0026lt;url\u0026gt; \u0026lt;where to clone\u0026gt; $ git clone \u0026lt;url\u0026gt; . // clone to current directory  View info about the remote repository:\n$ git remote -v // list repository info $ git branch -a // list all the branches, localy and remotely  Pull from the remote repository\n$ git pull origin master  Push changes to the remote repository after making local commitments:\n$ git push origin master // push to Git $ git push origin HEAD:refs/for/master // push to Gerrit  Push branch to the remote repository\n$ git push -u origin \u0026lt;branch_name\u0026gt; // -u is used so in future you can just simply use $git pull and $git push  References Git Development workflow: https://wcdma-confluence.rnd.ki.sw.ericsson.se/display/TAE/WMR+GIT+Development+workflow\nGit Basic Commands: https://wcdma-confluence.rnd.ki.sw.ericsson.se/display/TAE/Git+Basic+Commands\nGit Gerrit: https://wcdma-confluence.rnd.ki.sw.ericsson.se/display/TAE/Git+Gerrit\nMore:\nhttps://git-scm.com/docs\nhttps://gerrit-review.googlesource.com/Documentation/intro-user.html#gerrit\n","date":1555372800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555372800,"objectID":"8e6b496080d072a5968df1dac6b563f4","permalink":"/post/git-commands/","publishdate":"2019-04-16T00:00:00Z","relpermalink":"/post/git-commands/","section":"post","summary":"Configuration Set up global configuration variables if you haven\u0026rsquo;t done so\n$ git config --global user.name \u0026quot;\u0026lt;name\u0026gt;\u0026quot; $ git config --global user.email \u0026quot;\u0026lt;email\u0026gt;\u0026quot;  Git should automatically do a rebase when you do a pull, which is what you want\n$ git config branch.autosetuprebase always  To set up configuration for DiffMerge, follow the guide http://coding4streetcred.com/blog/post/configure-diffmerge-for-your-git-difftool.\nLocal Usage of Git Staging Check if there is any unstaged or untracked files","tags":["git"],"title":"Git commands","type":"post"},{"authors":null,"categories":["programming"],"content":" Introduction The R programming language, along with RStudio, has become one of the most popular tools for data analysis as it contains a large amount of open-source packages developed by a community of statisticians. However, R or RStudio is not ideal for Big Data analysis as mostly the data would not fit into R memory. On the other hand, Spark has become the leading platform for big-data analytics. It works with the system to distribute data across clusters and process data in parallel. Moreover it provides native bindings for different languages such as Java, Python, Scala, and R.\nsparklyr is an R package that allows us to analyze data in Spark from R. It supports dplyr, a popular tool for working with data frame like objects both in memory and out of memory, and many machine learning algorithms to run classifiers, regressions, and so on in Spark. It is extensible that you can create R packages that depend on sparklyr to call the full Spark API, such as H2O’s rsparkling, an R package that works with H2O’s machine learning algorithm. With sparklyr and rsparkling, we have access to all the tools in H2O for analysis with R and Spark.\n Connect to Spark Suppose that sparklyr has been successfully installed in your R environment. To get start with Spark using sparklyr and a local cluster,\nlibrary(sparklyr) spark_install() sc \u0026lt;- spark_connect(master = \u0026quot;local\u0026quot;) or if a Spark cluster has been made available to you\nsc \u0026lt;- spark_connect(master = \u0026quot;\u0026lt;cluster-master\u0026gt;\u0026quot;) When I run spark_connect(master = \u0026quot;local\u0026quot;), I got the error message\n\u0026quot;Java 9 is currently unsupported in Spark distributions unless you manually install Hadoop 2.8 and manually configure Spark. Please consider uninstalling Java 9 and reinstalling Java 8. To override this failure set \u0026#39;options(sparklyr.java9 = TRUE)\u0026#39;.\u0026quot; That’s because on my Windows 10 laptop, my JAVA_HOME was set to C:\\Java\\jdk, which has Version 11, in the system environment. I change it to\nJAVA_HOME = \u0026quot;C:\\Java\\jre1.8.0_151\u0026quot; Note that my Java folder was in C:\\Program Files (x86)\\.. and it created an issue when connecting to Spark. So I moved the folder directly to C:\\.. to solve the problem. Howoever, another error triggers when connecting to Spark\n---- Output Log ---- Error occurred during initialization of VM Could not reserve enough space for 2097152KB object heap It cannot allocate 2GB and this seems a common issue under Windows with a Java version using x86. To solve this, we can either install java x64 or reduce the default memory\nconfig \u0026lt;- spark_config() config[[\u0026quot;sparklyr.shell.driver-memory\u0026quot;]] \u0026lt;- \u0026quot;512m\u0026quot; sc \u0026lt;- spark_connect(master = \u0026quot;local\u0026quot;, config = config) Finally, I get connected to Spark! Now I can run analyses and build models using Spark from R.\nTo monitor and analyze execution, we can go to the Spark’s web interface:\nspark_web(sc) Once we are done with analysis, we can disconnect spark,\nspark_disconnect(sc)  Data Analysis Copy data to Spark The data set mtcars is a dataframe available in R. Run ?mtcars to see more details. To copy the data set into Apache Spark\ncars \u0026lt;- copy_to(sc, mtcars) Now we can access the data that was copied into Spark from R using the cars reference.\nTo read data from existing data sources in csv format and copy to Spark,\ncars \u0026lt;- spark_read_csv(sc, \u0026quot;cars.csv\u0026quot;) To export data as a csv file,\nspark_write_csv(cars, \u0026quot;cars.csv\u0026quot;) Other formats like plain text, JSON, JDBC are supported as well.\n Exploratory data analysis When using Spark from R to analyze data, most regular R functions, such as nrow, won’t work directly on the Spark reference cars. Instead, we can either use SQL through the DBI package or use dplyr (strongly preferred). Most of the data transformation made available by dplyr to work with local data frames are also available to use with a Spark connection. This means that a general approach to learning dplyr can be taken in order to gain more proficiency with data exploration and preparation with Spark. For example, to count how many records are available in cars,\ndplyr::count(cars) # = nrow(mtcars) To select columns, sample rows, and collect data from Spark,\ndf_in_r \u0026lt;- dplyr::select(cars, hp, mpg) %\u0026gt;% dplyr::sample_n(100) %\u0026gt;% dplyr::collect() Then we can apply regular R functions on the dataframe df_in_r, for example\ndim(df_in_r) plot(df_in_r) If a particular functionality is not available in Spark and no extension has been developed, we can distribute the R code across the Spark cluster. For example,\ncars %\u0026gt;% spark_apply(nrow) This is a powerful tools but comes with additional complexity that we should only use as a last resort option. We should learn how to do proper data analysis and modeling without having to distribute custom R code across our cluster!\nThe corrr package specializes in correlations. It contains friendly functions to prepare and visualize the results.\nlibrary(corrr) cars %\u0026gt;% correlate(use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;pearson\u0026quot;) %\u0026gt;% shave() %\u0026gt;% rplot() The sparklyr package also provides some functions for data transformation and exploratory data analysis. Those functions usually have sdf_ as a prefix.\n Modeling Spark MLlib is the component of Spark that allows one to write high level code to perform machine learning tasks on distributed data. Sparklyr provides an interface to the ML algorithms that should be familiar to R users. For example, you can run a linear regression as follows:\nmodel \u0026lt;- ml_linear_regression(cars, mpg ~ hp) model %\u0026gt;% ml_predict(copy_to(sc, data.frame(hp = 250 + 10 * 1:10))) %\u0026gt;% transmute(hp = hp, mpg = prediction) %\u0026gt;% full_join(select(cars, hp, mpg)) %\u0026gt;% collect() %\u0026gt;% plot() To retrieve additional statistics from the model,\nbroom::glance(model) Spark provides a wide range of algorithms and feature transformers. Those functions usually have ml_ or ft_ as prefix.\n  References https://therinspark.com/starting.html#starting-spark-web-interface\n ","date":1554854400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554854400,"objectID":"45f1a30cfc777dba3ed80fea62e2bba4","permalink":"/post/2019-04-10-sparklyr/","publishdate":"2019-04-10T00:00:00Z","relpermalink":"/post/2019-04-10-sparklyr/","section":"post","summary":"Introduction The R programming language, along with RStudio, has become one of the most popular tools for data analysis as it contains a large amount of open-source packages developed by a community of statisticians. However, R or RStudio is not ideal for Big Data analysis as mostly the data would not fit into R memory. On the other hand, Spark has become the leading platform for big-data analytics. It works with the system to distribute data across clusters and process data in parallel.","tags":["spark","big-data"],"title":"sparklyr (Spark in R)","type":"post"},{"authors":null,"categories":null,"content":" Introduction The ARIMA (autoregressive integrated moving average) models are also known as Box–Jenkins models. ARIMA models are applied in some cases where data show evidence of non-stationarity, where an initial differencing step (corresponding to the “integrated” part of the model) can be applied one or more times to eliminate the non-stationarity.\nThe AR part of ARIMA indicates that the evolving variable of interest is regressed on its own lagged (i.e., prior) values. The MA part indicates that the regression error is actually a linear combination of error terms whose values occurred contemporaneously and at various times in the past. The I (for “integrated”) indicates that the data values have been replaced with the difference between their values and the previous values (and this differencing process may have been performed more than once).\nWhen two out of the three model parameters are zeros, the model may be referred to based on the non-zero parameter, dropping “AR”, “I” or “MA” from the acronym describing the model. For example, \\(ARIMA (1,0,0)\\) is \\(AR(1)\\), \\(ARIMA(0,1,0)\\) is \\(I(1)\\), and \\(ARIMA(0,0,1)\\) is \\(MA(1)\\).\n AR(p) An autoregressive (AR) model is a representation of a type of random process. The AR model specifies that the output variable depends linearly on its own previous values and on a stochastic term. In general, the AR model of order \\(p\\), i.e. \\(AR(p)\\), is defined as \\[y_t = c + \\sum_{i=1}^p \\phi_i y_{t-i} +\\epsilon_t,\\] where \\(\\phi_1,\\cdots,\\phi_p\\) are the parameters, \\(c\\) is a constant, and \\(\\epsilon_t\\) is white noise often assumed following \\(N(0,\\sigma^2)\\).\nFor AR(1), \\(|\\phi|\u0026lt;1\\) is necessary for the process to be stationary, such that \\[E(y_t) = E(y_{t-1}) = \\mu,\\] \\[\\text{var}(y_t) = \\text{var}(y_{t-1})=\\frac{\\sigma^2}{1-\\phi^2} = \\sigma_y^2,\\] assuming \\(y_{t}\\)’s and \\(\\epsilon_t\\)’s are independent from each other. The condition \\(|\\phi|\u0026lt;1\\) appears in the variance term so that \\(\\sigma_y^2\\) is finite and positive. Note that \\(\\text{var}(y_t)\\) in AR(1) is larger than in AR(0) i.e. regular linear models without autoregressions.\n I(d) Differencing in statistics is a transformation applied to time-series data in order to make it stationary. Differencing removes the changes in the level of a time series, eliminating trend and seasonality and consequently stabilizing the mean of the time series. The differenced data is then used for the estimation of an ARMA model.\nThe I(1) model of first-order differencing can be written as \\[D(y_t) = y_t - y_{t-1} = \\epsilon_t,\\] and the I(2) model of second-order differencing can be written as \\[D^2(y_t) = D(y_t) - D(y_{t-1}) = y_t - 2y_{t-1}+y_{t-2} = \\epsilon_t,\\] where \\(D()\\) is the operator of differencing and \\(D^d(y_t) = D^{d-1}(y_t) - D^{d-1}(y_{t-1})\\).\nAnother method of differencing data is seasonal differencing, which involves computing the difference between an observation and the corresponding observation in the previous period. For example, \\[y\u0026#39;_t = y_t - y_{t-s},\\] where \\(s\\) is the duration of season. We denote it as \\(D_s(y_t)\\).\n MA(q) The moving average model of order \\(q\\), i.e. \\(MA(q)\\), is given as \\[y_t = \\mu + \\epsilon_t + \\sum_{i=1}^q\\theta_i\\epsilon_{t-i},\\] where \\(\\theta_1,\\cdots,\\theta_q\\) are the parameters, \\(\\mu\\) is the expectation of \\(y_t\\), and \\(\\epsilon_t, \\epsilon_{t-1},\\cdots\\) are white noise error terms.\n ARIMA(p,d,q) Non-seasonal ARIMA Non-seasonal ARIMA models are generally denoted \\(ARIMA(p,d,q)\\) where parameters \\(p, d, q\\) are non-negative integers, \\(p\\) is the order (number of time lags) of the autoregressive model, \\(d\\) is the degree of differencing (the number of times the data have had past values subtracted), and \\(q\\) is the order of the moving-average model. In general, an \\(ARIMA(p,d, q)\\) model is given as \\[D^d(y_t) = \\delta + \\sum_{i=1}^p\\phi_i D^d(y_{t-i}) + \\epsilon_t + \\sum_{i=1}^q \\theta_i \\epsilon_{t-i},\\] where \\(D^d(y_t)\\) is the \\(d\\)-order difference of \\(y_t\\).\n Seasonal ARIMA Seasonal ARIMA models are usually denoted \\(ARIMA(p,d,q)\\times(P,D,Q)_s\\), where \\(s\\) refers to the time span of repeating seasonal pattern, and the uppercase \\(P,D,Q\\) refer to the autoregressive, differencing, and moving average terms for the seasonal part of the ARIMA model.\nThe non-seasonal components are the same as in non-seasonal ARIMA. As for the seasonal components, we have, for example,\n Seasonal AR: \\(y_t = c + \\sum_{i=1}^P\\psi_i y_{t-si}\\)\n Seasonal MA: \\(y_t = \\mu+ \\epsilon_t + \\sum_{i=1}^Q\\eta_i\\epsilon_{t-si}\\)\n Seasonal I: \\(D^D_s(y_t) = D^{D-1}_s(y_t)- D_s^{D-1}(y_{t-s})\\)\n   Examples Some well-known special cases arise naturally or are mathematically equivalent to other popular forecasting models. For example:\n An \\(ARIMA(0,1,0)\\) model (or \\(I(1)\\) model) is given by \\(X_{t}=X_{t-1}+\\epsilon_{t}\\), which is simply a random walk.\n An \\(ARIMA(0,1,0)\\) with a constant, given by \\(X_{t}=c+X_{t-1}+\\epsilon_{t}\\), which is a random walk with drift.\n An \\(ARIMA(0,0,0)\\) model is a white noise model.\n An \\(ARIMA(0,1,2)\\) model is a Damped Holt’s model.\n An \\(ARIMA(0,1,1)\\) model without constant is a basic exponential smoothing model.\n An \\(ARIMA(0,2,2)\\) model is given by \\(X_{t}=2X_{t-1}-X_{t-2}+(\\alpha +\\beta -2)\\epsilon_{t-1}+(1-\\alpha )\\epsilon_{t-2}+\\epsilon_{t}\\), which is equivalent to Holt’s linear method with additive errors, or second-order exponential smoothing.\n    ","date":1554249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554249600,"objectID":"7e7b00ad1b6edccfd3fadc69c929fdf4","permalink":"/post/2019-04-03-arima/","publishdate":"2019-04-03T00:00:00Z","relpermalink":"/post/2019-04-03-arima/","section":"post","summary":"Introduction The ARIMA (autoregressive integrated moving average) models are also known as Box–Jenkins models. ARIMA models are applied in some cases where data show evidence of non-stationarity, where an initial differencing step (corresponding to the “integrated” part of the model) can be applied one or more times to eliminate the non-stationarity.\nThe AR part of ARIMA indicates that the evolving variable of interest is regressed on its own lagged (i.","tags":["arima","time-series"],"title":"ARIMA","type":"post"},{"authors":null,"categories":null,"content":" Introduction State-space models were originally developed by control engineers, particularly for applications that require continuous updating of the current position. An example, from the field of navigation systems, is updating an user equipment’s position. The models have also found increasing use in many types of time-series problems, including parameter estimation, smoothing, and prediction. Structural time-series models are state-space models for time-series data. They are useful in practice because they are\n flexible : a very large class of models can be expressed in state space forms, including all ARIMA and VARMA models;\n modular : the model can be assembled from a library of state-component sub-models to capture important features of the data. Several widely used state components are available for capturing the trend, seasonality, or effects of holidays.\n  The bsts R package is a tool for fitting structural time series models using Bayesian methods and bsts stands for Bayesian structural time series. The bsts can be configured for short term or long term forecasting, incorporating one or more seasonal effects, or fitting explanatory models if forecasting is not the primary goal.\n General Form A general form of (univariate) structural time-series model can be written as \\[\\begin{split} \u0026amp; y_t = Z_t^T \\alpha_t + \\epsilon_t, \\qquad (\\text{observation equation})\\\\ \u0026amp; \\alpha_{t+1} = T_t\\alpha_{t} + R_t\\eta_t, \\qquad (\\text{transition or state equation})\\\\ \u0026amp; \\epsilon_t\\sim N(0,\\sigma^2_t),\\quad \\eta_t \\sim N(0, Q_t) \\end{split}\\] where \\(y_t\\) is the observed value of a time series at time \\(t\\), \\(\\alpha_t\\) is a \\(m\\)-dimensional state vector, \\(Z_t\\) is a \\(m\\)-dimensional output vector, \\(T_t\\) is a \\(m\\times m\\) transition matrix, \\(R_t\\) is a \\(m\\times q\\) control matrix, \\(\\epsilon_t\\) is a scalar observation error, and \\(\\eta_t\\) is a \\(q\\)-dimensional system error with a \\(q\\times q\\) state-diffusion matrix \\(Q_t\\) where \\(q\\leq m\\).\n The observation equation links the observed data \\(y_t\\) with the unobserved latent state \\(\\alpha_t\\).\n The state vector \\(\\alpha_t\\) is of prime importance and is usually unobserved or partially known. Although it may not be directly observable, it is often reasonable to assume that we know how it changes over time, and we denote the updating equation by the transition or state equation above. This equation defines how the latent space evolves over time.\n The arrays \\(Z_t, T_t, R_t\\) typically contain a mix of known values (often 0 and 1) and unknown parameters. The 0’s and 1’s indicate which bits of \\(\\alpha_t\\) are relevant for a particular computation.\n The \\(\\epsilon_t\\) and \\(\\eta_t\\) are generally assumed to be serially uncorrelated and also to be uncorrelated with each other at all time periods. In practice, we often assume \\(\\epsilon_t\\sim N(0,\\sigma_t^2)\\).\n The term \\(R_t\\eta_t\\) allows us to incorporate state components of less than full ranks. A model for seasonality will be the most important example.\n  The analyst chooses the structure of \\(\\alpha_t\\) based on the specific data and task, such as whether it is for short or long term forecast, whether the data contains seasonal effects, and whether and how regressors are to be included. Many of these models are standard, and can be fit using a variety of tools, such as the StructTS function distributed with base R or one of several R packages for fitting these models, such as the dlm package for dynamic linear model. The bsts package handles all the standard cases, but it also includes several useful extensions.\n State Components Static intercept We can add a static intercept term to a model, \\[y_t = c+\\epsilon_t,\\] where \\(c\\) is a constant value. If the structural time-series model includes a traditional trend component (e.g. local level, local linear trend, etc) then a separate intercept is not needed (and will probably cause trouble, as it will be confounded with the initial state of the trend model). However, if there is no trend, or the trend is an AR process centered around zero, then adding a static intercept will shift the center to a data-determined value.\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddStaticIntercept(ss, y)  Trend Local level The local level model assumes the trend is a random walk: \\[\\begin{split} \u0026amp;y_t = \\mu_t +\\epsilon_t,\\\\ \u0026amp;\\mu_{t+1} = \\mu_{t} + \\eta_{t} \\end{split}\\]\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddLocalLevel(ss, y)  AR An autoregressive (AR) model is a representation of a type of random process. The AR model specifies that the time series \\(y_t\\) depends linearly on its own previous values and on a stochastic term. In general, the AR model of order \\(p\\), i.e. \\(AR(p)\\), can be written as \\[\\begin{split} \u0026amp;y_t = \\mu_t +\\epsilon_t,\\\\ \u0026amp;\\mu_{t+1} = \\sum_{i=0}^{p-1} \\phi_i \\mu_{t-i} + \\eta_{t} \\end{split}\\] where \\(\\phi_0,\\cdots,\\phi_{p-1}\\) are the parameters of the model. # R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddAr(ss, y, lags = p) The bsts package also supports sparse AR(p) process for large \\(p\\), where a spike and slab prior is applied on the autoregression coefficients \\(\\phi_0,\\cdots, \\phi_{p-1}\\). This model differs from the one in AddAr() only in that some of its coefficients may be set to zero.\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddAutoAr(ss, y, lags = p)  Local linear trend The local linear trend is a popular choice for modelling trends because it quickly adapts to local variation, which is desirable when making short-term predictions. However, this degree of flexibility may not be desired when making long-term predictions, as such predictions often come with implausibly wide uncertainty intervals.\nA local linear trend model for \\(y_t\\) can be written as, \\[\\begin{split} \u0026amp; y_t = \\mu_t +\\epsilon_t, \\\\ \u0026amp; \\mu_{t+1} = \\mu_{t} + \\delta_t + \\eta_{\\mu,t}, \\qquad \\text{(stochastic level component)}\\\\ \u0026amp; \\delta_{t+1} = \\delta_t + \\eta_{\\delta,t}, \\qquad \\text{(stochastic slope component)}\\\\ \u0026amp; \\eta_{\\mu, t} \\sim N(0,\\sigma^2_{\\mu, t}),\\quad \\eta_{\\delta, t} \\sim N(0,\\sigma^2_{\\delta, t}) \\end{split}\\] where \\(\\mu_t\\) is the value of the trend at time \\(t\\), \\(\\delta_t\\) is the expected increase in \\(\\mu\\) between time \\(t\\) and \\(t+1\\) so it can be thought of as the slope at time \\(t\\), \\(\\eta_{\\mu,t}\\) and \\(\\eta_{\\delta, t}\\) are error terms independent from each other. A local linear trend allows both level (\\(\\mu_t\\)) and slope (\\(\\delta_t\\)) to be stochastic. It assumes that both the level and the slope follow random walks.\nThe model can also be expressed in the general form \\[\\begin{split} \u0026amp; y_t = [1\\quad 0]\\left[\\begin{matrix}\\mu_t\\\\\\delta_t\\end{matrix}\\right] +\\epsilon_t, \\\\ \u0026amp; \\left[\\begin{matrix}\\mu_{t+1}\\\\\\delta_{t+1}\\end{matrix}\\right] = \\left[\\begin{matrix}1 \u0026amp; 1\\\\ 0 \u0026amp; 1 \\end{matrix}\\right] \\left[\\begin{matrix}\\mu_t\\\\\\delta_t\\end{matrix}\\right] + \\left[\\begin{matrix}1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\end{matrix}\\right] \\left[\\begin{matrix}\\eta_{\\mu, t}\\\\\\eta_{\\delta, t}\\end{matrix}\\right], \\end{split}\\] where \\(Z_t = (1,0)^T\\), \\(\\alpha_t = (\\mu_t, \\delta_t)^T\\), \\(T_t = \\left[\\begin{smallmatrix}1 \u0026amp; 1\\\\ 0 \u0026amp; 1 \\end{smallmatrix}\\right]\\), \\(R_t=\\left[\\begin{smallmatrix}1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\end{smallmatrix}\\right]\\), and \\(\\eta_t = (\\eta_{\\mu,t}, \\eta_{\\delta, t})^T\\).\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddLocalLinearTrend(ss, y)  Semi-local linear trend The semi-local linear trend is similar to the local linear trend, but more useful for long-term forecasting. The model can be written as \\[\\begin{split} \u0026amp; y_t = \\mu_t +\\epsilon_t, \\\\ \u0026amp; \\mu_{t+1} = \\mu_{t} + \\delta_t + \\eta_{\\mu,t}, \\qquad \\text{(stochastic level component)}\\\\ \u0026amp; \\delta_{t+1} = a + \\phi\\times (\\delta_t-a) + \\eta_{\\delta,t}, \\qquad \\text{(stochastic slope component)}\\\\ \u0026amp; \\eta_{\\mu, t} \\sim N(0,\\sigma^2_{\\mu, t}),\\quad \\eta_{\\delta, t} \\sim N(0,\\sigma^2_{\\delta, t}) \\end{split}\\] where the slope component \\(\\delta_{t+1}\\) is modeled by an AR(1) process centered at value \\(a\\). A stationary AR(1) process is less variable than a random walk so it often gives more reasonable uncertainty estimates when making long term forecasts.\nThe model can be expressed in the general form with \\(Z_t = (1,0, a)^T\\), \\(\\alpha_t = (\\mu_t+a, \\delta_t-a, -1)^T\\), \\(T_t = \\left[\\begin{smallmatrix}1 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; \\phi \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{smallmatrix}\\right]\\), \\(R_t=\\left[\\begin{smallmatrix}1 \u0026amp; 0 \\\\ 0 \u0026amp; 1\\\\0\u0026amp;0 \\end{smallmatrix}\\right]\\), and \\(\\eta_t = (\\eta_{\\mu,t}, \\eta_{\\delta, t})^T\\).\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddSemilocalLinearTrend(ss, y)   Seasonality Regression with Seasonal Dummy Variables There are several commonly used state-component models to capture seasonality. The most frequently used model in the time domain is \\[\\begin{split} \u0026amp; y_t = \\gamma_t +\\epsilon_t, \\\\ \u0026amp; \\gamma_{t+d} = - \\sum_{i=0}^{s-2}\\gamma_{t-i\\times d} + \\eta_{\\gamma, t}, \\end{split}\\] where \\(s\\) is the number of seasons and \\(d\\) is the seasonal duration (number of time periods in each season, often set to 1). The model can be thought of as a regression on \\(s\\) dummy variables representing \\(s\\) seasons and \\(\\gamma_{t}\\) denotes their joint contribution to the observed response \\(y_t\\). The mean of \\(\\gamma_{t+d}\\) is such that the total seasonal effect is zero when summed over \\(s\\) seasons (i.e. \\(E(\\gamma_{t+d}+\\sum_{i=0}^{s-2}\\gamma_{t-i\\times d}) = 0\\)). The model can be rewritten as \\[\\begin{split} \u0026amp; y_t = [1\\quad 0 \\quad \\cdots\\quad 0]\\left[\\begin{matrix}\\gamma_{t}\\\\\\gamma_{t-d}\\\\ \\vdots\\\\ \\gamma_{t-(s-2)d}\\end{matrix}\\right] +\\epsilon_t, \\\\ \u0026amp; \\left[\\begin{matrix}\\gamma_{t+d}\\\\\\gamma_t\\\\\\gamma_{t-d}\\\\ \\vdots\\\\ \\gamma_{t-(s-4)d}\\\\ \\gamma_{t-(s-3)d}\\end{matrix}\\right] = \\left[\\begin{matrix} -1 \u0026amp; - 1 \u0026amp; \\cdots \u0026amp; -1 \u0026amp; -1 \\\\ 1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp;0\u0026amp; 0\\\\ 0 \u0026amp; 1 \u0026amp; \\cdots \u0026amp; 0 \u0026amp;0 \\\\ \\vdots \u0026amp;\\vdots \u0026amp;\\vdots \u0026amp;\\vdots \u0026amp;\\vdots \u0026amp;\\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; 0 \\\\ \\end{matrix}\\right] \\left[\\begin{matrix}\\gamma_{t}\\\\\\gamma_{t-d}\\\\\\gamma_{t-2d}\\\\\\vdots \\\\ \\gamma_{t-(s-3)d}\\\\ \\gamma_{t-(s-2)d}\\end{matrix}\\right] + \\left[\\begin{matrix}1\\\\0\\\\0\\\\ \\vdots\\\\ 0\\\\ 0\\end{matrix}\\right]\\eta_{\\gamma, t} \\end{split}\\]\nThe seasonal model can be generalized to allow for multiple seasonal components with different periods.\n# R code # Suppose that y is a time series collected hourly ss \u0026lt;- list() # daily seasonality ss \u0026lt;- bsts::AddSeasonal(ss, y, nseasons = 24, season.duration = 1) # weely seasonality ss \u0026lt;- bsts::AddSeasonal(ss, y, nseasons = 7, season.duration = 24)  Trigonometric Seasonal model Another way to model seasonality is to use trigonometric seasonal model, \\[\\begin{split} \u0026amp; y_t = \\gamma_t +\\epsilon_t, \\\\ \u0026amp; \\gamma_{j, t+1} = \\gamma_{j,t}\\times \\cos(\\lambda_j) - \\gamma^*_{j,t}\\times \\sin(\\lambda_j) + \\omega_{j, t},\\\\ \u0026amp; \\gamma^*_{j, t+1} = \\gamma^*_{j,t}\\times \\cos(\\lambda_j) - \\gamma_{j,t}\\times \\sin(\\lambda_j) + \\omega^*_{j,t},\\\\ \\end{split}\\] where \\(\\gamma_t = \\sum_{j=1}^{k}\\gamma_{j,t}\\), \\(\\lambda_j = 2\\pi j/s\\) is the \\(j\\)-th seasonal frequency, \\(j = 1,\\cdots, k\\), and \\(s\\) is the number of time steps required for the longest cycle to repeat (i.e. number of seasosns).\n# R code ss \u0026lt;- list() # The harmonic method is strongly preferred to the direct method. # For a time series collected hourly with daily # seasonality, we can try # the component below, where frequencies = 1:4 specifies the frequencis of sin, cos functions we will use. ss \u0026lt;- bsts::AddTrig(ss, y, period = 24, frequencies = 1:4, method = \u0026quot;harmonic\u0026quot;)   Linear regression The covariates in structural time series models are assumed to be contemporaneous. The coefficients of the contemporaneous covariates \\(\\mathbf{x}_t\\) can be static or time-varying.\nA static regression can be written in state-space form by setting \\(Z_t = \\beta^T \\mathbf{x}_t\\) and \\(\\alpha_t =1\\), where \\(\\beta\\) is static.\n# R code ss \u0026lt;- list() bsts::bsts(y ~ x, ss, niter = 500) A dynamic regression component can be written as \\[\\begin{split} \u0026amp; \\mathbf{x}_t^T\\beta_t = \\sum_{j=1}^J x_{j,t} \\beta_{j,t}\\\\ \u0026amp; \\beta_{j, t+1} = \\beta_{j,t} + \\eta_{\\beta,j,t}, \\end{split}\\] where \\(\\beta_{j,t}\\) is the coefficient for the \\(j\\)-th covariate \\(x_{j,t}\\) at time \\(t\\). The state-space form is given as \\(Z_t = \\mathbf{x}_t, \\alpha_t =\\beta_t, T_t = R_t = I_{J\\times J}\\).\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddDynamicRegression(ss, y ~ x) bsts::bsts(y, ss, niter = 500)  Assemble multiple state components Independent state components can be combined by concatenating their observation vectors \\(Z_t\\) and arranging the other model matrices as elements in a block diagonal matrix. For example, we can combine the local linear trend with seasonality and have the following model matrices: \\[Z_t = \\left[\\begin{smallmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\vdots\\\\ 0\\end{smallmatrix}\\right], T_t = \\left[\\begin{smallmatrix} 1 \u0026amp; 1 \u0026amp; \\\\ 0 \u0026amp; 1 \u0026amp; \\\\ \u0026amp; \u0026amp; -1 \u0026amp; - 1 \u0026amp; \\cdots \u0026amp; -1 \u0026amp; -1 \\\\ \u0026amp; \u0026amp; 1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp;0\u0026amp; 0\\\\ \u0026amp; \u0026amp; 0 \u0026amp; 1 \u0026amp; \\cdots \u0026amp; 0 \u0026amp;0 \\\\ \u0026amp; \u0026amp; \\vdots \u0026amp;\\vdots \u0026amp;\\vdots \u0026amp;\\vdots \u0026amp;\\vdots \u0026amp;\\\\ \u0026amp; \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 1 \u0026amp; 0 \\\\ \u0026amp; \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; 0 \\\\ \\end{smallmatrix}\\right], R_t=\\left[\\begin{smallmatrix} 1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\\\ \u0026amp; \u0026amp; 1 \\\\ \u0026amp; \u0026amp; 0 \\\\ \u0026amp; \u0026amp; \\vdots \\\\ \u0026amp; \u0026amp; 0 \\\\ \\end{smallmatrix}\\right] \\]\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddLocalLinearTrend(ss, y) ss \u0026lt;- bsts::AddSeasonality(ss, y, nseason = s, season.duration = d) bsts::bsts(y, ss, niter = 500) Similarly, we can add other state components such as Regression, Local level, AR process, Random walk for holiday effect, etc (see bsts Package for more details). As mentioned in the Introduction, the model is modular and can be easily extended by using the bsts package. For example,\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddLocalLevel(ss, y) ss \u0026lt;- bsts::AddAr(ss, y) ss \u0026lt;- bsts::AddSeasonal(ss, y, nseasons = 24) ss \u0026lt;- bsts::AddDynamicRegression(ss, y ~ x1) bsts::bsts(y ~ x2, ss, niter = 500) Some examples of application to real data analyses can be found here.\n  Model diagnostic Prediction errors As part of the model fitting process, the algorithm in bsts generates the one-step-ahead prediction errors \\(y_tb\u0008\u0012E(y_t|Y_{tb\u0008\u00121},\\theta)\\) , where \\(Y_{tb\u0008\u00121}=y_1,\\cdots,y_{tb\u0008\u00121}\\), and the vector of model parameters \\(\\theta\\) is fixed at its current value in the MCMC algorithm. The one-step-ahead prediction errors can be obtained from the bsts model by calling\nbsts.prediction.errors(model1) The one step prediction errors are a useful diagnostic for comparing several bsts models that have been fit to the same data. They are used to implement the function CompareBstsModels, which is called as shown below.\nCompareBstsModels(list(\u0026quot;Model 1\u0026quot; = model1, \u0026quot;Model 2\u0026quot; = model2, \u0026quot;Model 3\u0026quot; = model3), colors = c(\u0026quot;black\u0026quot;, \u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;))  Model assumptions In BSTS models, the residual term is often assumed to follow a Gaussian distribution. It is important to check the validity of such assumption to see if the model is valid or not.\nThe output of bsts model contains a matrix of Monte Carlo draws of residual errors. Each row is a Monte Carlo draw, and each column is an observation.\nThe qqdist function sorts the columns of draws by their mean, and plots the resulting set of curves against the quantiles of the standard normal distribution. A reference line is added, and the mean of each column of draws is represented by a blue dot. If the dots fall around the straight line, the normality assumption holds well for the residuals. If the dots depart greatly from the line, the normality assumption may violate. In this case, we may either do data transformation to obtain more normally distributed data or assume a different distribution on the data (e.g. t-distribution)\nThe AcfDist function plots the posterior distribution of the autocorrelation function (ACF) of the residuals using a set of side-by-side boxplots. If the boxplot of lag \\(k\\) contains 0, we may consider the residuals are uncorrelated at lag \\(k\\). If the ACF does not dampen out (i.e. falling to zero) within about 15 to 20 lags, the residual term is nonstationary and we should try a different model.\n  References Steven L. Scott. (2017). Fitting Bayesian structural time series with the bsts R package. http://www.unofficialgoogledatascience.com/2017/07/fitting-bayesian-structural-time-series.html.\nChatfield, Chris. (2016). The analysis of time series: an introduction. CRC press.\nMontgomery, Douglas C., Cheryl L. Jennings, and Murat Kulahci. (2015). Introduction to time series analysis and forecasting. John Wiley \u0026amp; Sons.\n ","date":1553126400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553126400,"objectID":"5a43568427900f38d6e1a6d76c89c1f3","permalink":"/post/2019-03-21-bsts/","publishdate":"2019-03-21T00:00:00Z","relpermalink":"/post/2019-03-21-bsts/","section":"post","summary":"Introduction State-space models were originally developed by control engineers, particularly for applications that require continuous updating of the current position. An example, from the field of navigation systems, is updating an user equipment’s position. The models have also found increasing use in many types of time-series problems, including parameter estimation, smoothing, and prediction. Structural time-series models are state-space models for time-series data. They are useful in practice because they are","tags":["bsts","time-series"],"title":"Structural Time-Series Models","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c8bc6f47bdfa5be820b3e153b7d892f5","permalink":"/publication/publications/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/publications/","section":"publication","summary":"","tags":null,"title":"","type":"publication"}]