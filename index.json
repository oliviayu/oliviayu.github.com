[{"authors":null,"categories":null,"content":"I completed my PhD program in Statistics in 2018 winter, under the supervision of Prof. Lang Wu in the Department of Statistics  at the University of British Columbia (UBC).\nI finished my Master\u0026rsquo;s program in Statistics at UBC in 2013. In 2011, I received my Bachelor\u0026rsquo;s degree in Statistics from Zhejiang University of Finance and Economics in China. .\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/admin/","section":"author","summary":"I completed my PhD program in Statistics in 2018 winter, under the supervision of Prof. Lang Wu in the Department of Statistics  at the University of British Columbia (UBC).\nI finished my Master\u0026rsquo;s program in Statistics at UBC in 2013. In 2011, I received my Bachelor\u0026rsquo;s degree in Statistics from Zhejiang University of Finance and Economics in China. .","tags":null,"title":"Tingting Yu","type":"author"},{"authors":null,"categories":null,"content":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.main]] menu links to it in the config.toml.\n","date":1536444000,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536444000,"objectID":"c3224f3a64174f08aaf31e1f1d16ffd3","permalink":"/tutorial/","publishdate":"2018-09-09T00:00:00+02:00","relpermalink":"/tutorial/","section":"tutorial","summary":"This feature can be used for publishing content such as:\n Project or software documentation Online courses Tutorials  The parent folder may be renamed, for example, to docs for project documentation or course for creating an online course.\nTo disable this feature, either delete the parent folder, or set draft = true in the front matter of all its pages.\nAfter renaming or deleting the parent folder, you may wish to update any [[menu.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f4d7d8e2a0129bf0277ebe9bf2ca8cce","permalink":"/about/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/about/","section":"about","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f38631c06dc52d51e25323771c266097","permalink":"/post/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"1a618c6ad5e840d40b2ef44df562adec","permalink":"/author/skills/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/skills/","section":"author","summary":"","tags":null,"title":null,"type":"author"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"aa2f8256064e29f2b3aec489c007f79a","permalink":"/experience/experience/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/experience/experience/","section":"experience","summary":"","tags":null,"title":"Experience","type":"experience"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"96dd649331fb96742c48729fc7815814","permalink":"/recent_posts/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/recent_posts/","section":"","summary":"","tags":null,"title":"Recent Posts","type":"page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7ecdd4a6de39fb3c3d4ff43482669f6a","permalink":"/project/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/projects/","section":"project","summary":"","tags":null,"title":"Projects","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"523e67a9409657937fe78a2f6d2cbdfc","permalink":"/talk/talks/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talk/talks/","section":"talk","summary":"","tags":null,"title":"Recent \u0026 Upcoming Talks","type":"talk"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"20fbb49702cd08433cf33f5cad553745","permalink":"/author/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/contact/","section":"author","summary":"","tags":null,"title":null,"type":"author"},{"authors":null,"categories":["data-manipulation"],"content":" Aggregation library(magrittr) set.seed(1) ex_dat \u0026lt;- data.frame(group = rep(1:3, each = 2), y = rnorm(6), x = rnorm(6)) ex_dat ## group y x ## 1 1 -0.6264538 0.4874291 ## 2 1 0.1836433 0.7383247 ## 3 2 -0.8356286 0.5757814 ## 4 2 1.5952808 -0.3053884 ## 5 3 0.3295078 1.5117812 ## 6 3 -0.8204684 0.3898432 Summarise selected columns by group\ndplyr::group_by(ex_dat, group) %\u0026gt;% dplyr::summarise(total_y = sum(y)) ## # A tibble: 3 x 2 ## group total_y ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 -0.443 ## 2 2 0.760 ## 3 3 -0.491 Summarise all the columns by group\ndplyr::group_by(ex_dat, group) %\u0026gt;% dplyr::summarise_all(sum) # you can replace sum() by any function ## # A tibble: 3 x 3 ## group y x ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 -0.443 1.23 ## 2 2 0.760 0.270 ## 3 3 -0.491 1.90  Reshape Reshaping data is often needed before ploting.\nlong_dat \u0026lt;- reshape2::melt(ex_dat, id.vars = \u0026quot;group\u0026quot;) long_dat ## group variable value ## 1 1 y -0.6264538 ## 2 1 y 0.1836433 ## 3 2 y -0.8356286 ## 4 2 y 1.5952808 ## 5 3 y 0.3295078 ## 6 3 y -0.8204684 ## 7 1 x 0.4874291 ## 8 1 x 0.7383247 ## 9 2 x 0.5757814 ## 10 2 x -0.3053884 ## 11 3 x 1.5117812 ## 12 3 x 0.3898432 reshape2::dcast(long_dat, group ~ variable, mean) ## group y x ## 1 1 -0.2214052 0.6128769 ## 2 2 0.3798261 0.1351965 ## 3 3 -0.2454803 0.9508122  Complete a data frame df \u0026lt;- tibble::tibble( group = c(1:2, 1), item_id = c(1:2, 2), item_name = c(\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;), value1 = 1:3, value2 = 4:6 ) df %\u0026gt;% tidyr::complete(group, tidyr::nesting(item_id, item_name)) ## # A tibble: 4 x 5 ## group item_id item_name value1 value2 ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 1 1 a 1 4 ## 2 1 2 b 3 6 ## 3 2 1 a NA NA ## 4 2 2 b 2 5 df %\u0026gt;% tidyr::complete(group, item_id, item_name) ## # A tibble: 8 x 5 ## group item_id item_name value1 value2 ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; ## 1 1 1 a 1 4 ## 2 1 1 b NA NA ## 3 1 2 a NA NA ## 4 1 2 b 3 6 ## 5 2 1 a NA NA ## 6 2 1 b NA NA ## 7 2 2 a NA NA ## 8 2 2 b 2 5  Extract subset of data Extract variables\ndf %\u0026gt;% dplyr::select(group) df %\u0026gt;% dplyr::select(tidyselect::starts_with(\u0026quot;item_\u0026quot;)) df %\u0026gt;% dplyr::select(tidyselect::ends_with(\u0026quot;_name\u0026quot;)) df %\u0026gt;% dplyr::select(tidyselect::num_range(\u0026quot;value\u0026quot;, 1:2)) df %\u0026gt;% dplyr::select(tidyselect::contains(\u0026quot;item\u0026quot;)) df %\u0026gt;% dplyr::select(tidyselect::matches(\u0026quot;value.\u0026quot;)) Filter rows\ndf %\u0026gt;% dplyr::filter(group == 1) df %\u0026gt;% dplyr::distinct(group, .keep_all = TRUE) df %\u0026gt;% dplyr::slice(2:3) # select rows by position df %\u0026gt;% dplyr::top_n(2, value1) # select top 2 entries in value1  ","date":1565136000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565136000,"objectID":"e3597f69a929c780d466e30563fb06bd","permalink":"/post/2019-08-07-data_manipulation/","publishdate":"2019-08-07T00:00:00Z","relpermalink":"/post/2019-08-07-data_manipulation/","section":"post","summary":"Aggregation library(magrittr) set.seed(1) ex_dat \u0026lt;- data.frame(group = rep(1:3, each = 2), y = rnorm(6), x = rnorm(6)) ex_dat ## group y x ## 1 1 -0.6264538 0.4874291 ## 2 1 0.1836433 0.7383247 ## 3 2 -0.8356286 0.5757814 ## 4 2 1.5952808 -0.3053884 ## 5 3 0.3295078 1.5117812 ## 6 3 -0.8204684 0.3898432 Summarise selected columns by group\ndplyr::group_by(ex_dat, group) %\u0026gt;% dplyr::summarise(total_y = sum(y)) ## # A tibble: 3 x 2 ## group total_y ## \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 1 -0.","tags":["data","r"],"title":"Data manipulation in R","type":"post"},{"authors":null,"categories":["data-manipulation"],"content":" Introduction Structured Query Language (SQL) is a standard computer language for relational database management and data manipulation. It can be used to read, write, and update data. For data scientists, it is mainly used for data retrieval. There are several relational database management systems, such as Oracle, MySQL, and SQLite. Depending on the system you are using, the SQL syntax may be a little bit different.\nRetrieve data Use SELECT statement to query database, filtered by some conditions (optional). The [ ] is used to state optional clauses. To select all columns, use * after the SELECT keyword.\nSELECT \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt; FROM \u0026lt;tablename\u0026gt; [WHERE \u0026lt;condition\u0026gt;];  Conditional selections used in the WHERE clause:\n= Equal \u0026lt;\u0026gt; Not equal to \u0026gt; Greater than \u0026lt; Less than \u0026gt;= Greater than or equal \u0026lt;= Less than or equal BETWEEN AND Within a range IS NULL Is a null LIKE Pattern matching operator IN (\u0026lt;val1\u0026gt;, \u0026lt;val2\u0026gt;, ...) OR AND NOT   Sometimes IN and OR can accomplish the same thing. But in general, IN executes faster than OR and it allows to use another SELECT for subqueries.\n SQL processes AND before OR. Use ( ) when using AND and OR together to avoid confusion in the order of operations.\n  Wildcards for pattern matching:\n Using % for pattern matching: \u0026lsquo;%a\u0026rsquo;, end with a; \u0026lsquo;a%\u0026rsquo;, start with a; \u0026lsquo;%a%\u0026rsquo;, with a in between; \u0026lsquo;a%z\u0026rsquo;, start with a and end with z; \u0026lsquo;a%@gmail.com\u0026rsquo;, grab gmail addresses start with a.\n Using underscore _ for matching a single character: \u0026lsquo;_day\u0026rsquo;, grab four-letter words that end with \u0026lsquo;day\u0026rsquo;.\n Wildcards take longer to run than regular operators. Avoid using them if they can be replaced by other operators.\n  Example\nThe code below select two columns from a table named nameInfo and only select rows where the lastname ends in \u0026ldquo;son\u0026rdquo;.\nSELECT firstname, lastname FROM nameInfo WHERE lastname LIKE '%son';  Create table Use CREATE TABLE statement to create a new table, with optional constraints associated with each column respectively. The table and column names must start with a letter and can be followed by letters, numbers, or underscores The maximum length of a name is 30 characters.\nCREATE TABLE \u0026lt;tablename\u0026gt; (\u0026lt;column1\u0026gt; \u0026lt;data type\u0026gt; [constraint], \u0026lt;column2\u0026gt; \u0026lt;data type\u0026gt; [constraint] );  Use CREATE TEMPORARY TABLE statement to create a temporary table. It is faster to create a temporary table than a real table. However, temporary tables will be deleted when current session is terminated.\nCREATE TEMPORARY TABLE \u0026lt;temp_tablename\u0026gt; AS ( SELECT * FROM \u0026lt;tablename\u0026gt; [WHERE \u0026lt;conditions\u0026gt;] )  Common data types in SQL\nchar(size)\tCharacter string with a fixed length. Varchar(size)\tCharacter string with a maximum number of length. date\tDate value number(size)\tNumber value with a maximum number of integer digits. number(size, d)\tNumber value with a maximum number of \u0026quot;size\u0026quot; integer digits and a maximum number of \u0026quot;d\u0026quot; fraction digits. decimal(n, d)  Common constraints\nUNIQUE\tNo two records can have the same value in a particular column. NOT NULL\tA column can't be left blank. PRIMARY KEY Defines a unique identification of each record (or row) in a table. Cannot contain NULL.  Example\nCREATE TABLE nameInfo (idnumber number(12) UNIQUE, firstname Varchar(20), lastname Varchar(20), age number(3), country Varchar(10) );  Insert and delete rows Use INSERT INTO statement to insert rows into a table. All strings should be enclosed in single quotes, for example \u0026lsquo;September\u0026rsquo;.\nINSERT INTO \u0026lt;tablename\u0026gt; (col_1, ... , col_n) VALUES (value_1, ..., value_n);  Use DELETE FROM statement to delete rows from a table.\nDELETE FROM \u0026lt;tablename\u0026gt; WHERE \u0026lt;col_1\u0026gt; OPERATOR \u0026lt;value_1\u0026gt; [AND|OR \u0026lt;col_2\u0026gt; OPERATOR \u0026lt;value_2\u0026gt;];  Examples\nINSERT INTO nameInfo (idnumber, firstname, lastname, age, country) VALUES (1234567, 'John', 'Lee', 45, 'Canada'); DELETE FROM nameInfo WHERE lastname = 'May';  Insert column Add column to a table in a database:\nAFTER TABLE \u0026lt;tablename\u0026gt; ADD \u0026lt;columnname\u0026gt; \u0026lt;datatype\u0026gt;;  SELECT \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt;, \u0026lt;col1\u0026gt; + \u0026lt;col2\u0026gt; AS \u0026lt;col3\u0026gt;  Update records Use UPDATE statement to update records that match a specified criteria.\nUPDATE \u0026lt;tablename\u0026gt; SET \u0026lt;columnname\u0026gt; = \u0026lt;newvalue\u0026gt; [, \u0026lt;nextcolumn\u0026gt; = \u0026lt;newvalue2\u0026gt;, ... ] WHERE \u0026lt;columnname\u0026gt; OPERATOR \u0026lt;value\u0026gt; [AND|OR \u0026lt;column\u0026gt; OPERATOR \u0026lt;value\u0026gt;];  Example\nUPDATE nameInfo SET lastname = 'Li', age = 48, WHERE lastname = 'Lee' AND firstname = 'John';  Drop a table Use DROP TABLE command to delete a table and all rows in the table. It is different from deleting all the records in the table. The former removes the table definition as well as all of its rows and the latter leaves the table including column and constraint information.\nDROP TABLE \u0026lt;tablename\u0026gt;  Sort a table Use ORDER BY statement to sort a table. It must be the last clause in a select statement.\nSELECT \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt; FROM \u0026lt;tablename\u0026gt; ORDER BY \u0026lt;col1\u0026gt; DESC, \u0026lt;col2\u0026gt; ASC, \u0026lt;col3\u0026gt; ASC;  You can sort by a column not retrieved and use DESC or ASC for descending or ascending (default) order.\nAggregate functions AVG() COUNT() MIN() MAX() SUM()   Rows containing NULL values are ignored by AVG(), MIN(), MAX().\n COUNT(*): count all the rows containing values or NULL;\n COUNT(\u0026lt;colname\u0026gt;): count all the rows in a specific column ignoring NULL values;\n Use DISTINCT on aggregate functions. For example, COUNT( DISTINCT \u0026lt;colname\u0026gt;).\n  Examples\nSELECT AVG(score) AS average_score  Group data Use GROUP BY clause to group data and use HAVING clause for filtering for groups. They are used after WHERE clause and hence rows filtered out by WHERE will not be included in GROUP BY clause.\nSELECT \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt;, [some aggregated calculations] FROM \u0026lt;tablename\u0026gt; GROUP BY \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt; [HAVING \u0026lt;condition\u0026gt;];  Every column in your SELECT statement must be present in a GROUP BY clause, except for aggregated calculations.\nExample\nSELECT customerID, COUNT(*) AS orders FROM Orders GROUP BY customerID HAVING COUNT(*) \u0026gt;= 2 ;  Using subqueries Subqueries are queries embedded into other queries. Since data is often stored in multiple tables, subqueries are useful when it comes to getting information from multiple tables. Moreover, they are often used for adding additional criteria, such as filtering criteria, from another table into your query. Subquery selects can only retrieve a single column.\nThere is no limit to the number of subqueries you can have. But the performance in obtaining the results slows down when the subqueries are deeply nested.\nExample\nSELECT studentID, firstname, lastname, major FROM studentList WHERE studentiID IN ( SELECT studentID FROM gradeList WHERE score \u0026gt; 80 );  Joining tables A join allows you to retrieve the data from multiple tables in just one query. The result only exists for the duration of the query execution.\nCartesian (cross) joins A Cartesian join allows you to take each record from the first table and match it with all of the records from the second table. If the first table contains x rows and second table contains y rows, you will have x*y rows in the end result. It is computationally taxing and is not matching on anything. So it is not frequently used.\nSELECT \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt;, \u0026lt;col3\u0026gt; FROM \u0026lt;table1\u0026gt; CROSS JOIN \u0026lt;table2\u0026gt;;  Inner joins An inner join is used to select records that have matching values in both tables on some keys.\nSELECT \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt;, \u0026lt;col3\u0026gt; FROM \u0026lt;table1\u0026gt; INNER JOIN \u0026lt;table2\u0026gt; ON \u0026lt;prequalified key1\u0026gt; = \u0026lt;prequalified key2\u0026gt; ;  Example\nSELECT studentID, firstname, lastname, score FROM studentList INNER JOIN gradeList ON studentList.studentID = gradeList.studentID;  Aliases and self joins An alias is helpful because it can help you by just shortening names and simplifying how we are pre-qualifying them. It doesn\u0026rsquo;t rewrite anything of the table permanently and is only stored for the duration of the query.\nExample\nSELECT studentID, firstname, lastname FROM studentList AS stud, gradeList AS grade WHERE stud.studentID = grade.studentID ;  A self join takes the table and treat it like two separate tables. The following example matches customers that are from the same city.\nExample\nSELECT A.name AS name1, B.name AS name2, A.city FROM Customers A, Customers B WHERE A.customerID = B.customberID AND A.city = B.city ORDER BY A.city;  Left, right, full outer joins The left join returns all the records from the table on the left side and the matched records from the right table. The following example selects all customers and any orders they might have:\nSELECT C.name, O.orderID FROM Customers C LEFT JOIN Orders O ON C.customerID = O.customerID ORDER BY C.name  The difference between the right and left joins is the order the tables are relating. Right joins can be turned into left joins by reversing the order of the tables.\nThe full outer join returns all records when there is a match in either left or right table. The following example selects all customers and all orders.\nSELECT C.name, O.orderID FROM Customers C FULL OUTER JOIN Orders O ON C.customerID = O.customerID ORDER BY C.name ;  Unions The UNION is used to combine the result set of two or more SELECT statements. Each SELECT statement within UNION must have the same number of columns and the columns must be in the same order with similar data types.\nSELECT \u0026lt;colnames\u0026gt; FROM \u0026lt;table1\u0026gt; UNION SELECT \u0026lt;colnames\u0026gt; FROM \u0026lt;table2\u0026gt;  The following example selects the German cities that have suppliers.\nSELECT city, country FROM Customers WHERE country = 'germany' UNION SELECT city, country FROM supplier WHERE country = 'germany' ORDER BY city;  Working with text strings Concatenations Use || to concatenate strings. SQL server supports + instead of ||.\nSELECT CompanyName, ContactName, CompanyName || '(' || ContactName || ')' FROM customers  Trimming Use LTRIM, RTRIM, TRIM to trim the leading, trailing, or both space from a string.\nSELECT TRIM(\u0026quot;\tHello.\t\u0026quot;) AS TrimmedString  Substring Use SUBSTR to return the specified number of characters from a particular position of a given string.\nSELECT firstname, SUBSTR (firstname, 2, 4)\t# pull 4 characters, starting at the 2nd character FROM employees  Upper and lower SELECT UPPER(firstname) FROM employees; SELECT LOWER(firstname) FROM employees;  Working with date and time strings SQLite supports 5 date and time functions:\nDATE(timestring, modifier, modifier, ...) TIME(timestring, modifier, modifier, ...) DATETIME(timestring, modifier, modifier, ...) JULIANDAY(timestring, modifier, modifier, ...) # Extract certain parts of a date or time string. # format components: %Y %m %d %H %M %S %s STRFTIME(format, timestring, modifier, modifier, ...)  A timestring can be in any of the following formats\nYYYY-MM-DD YYYY-MM-DD HH:MM YYYY-MM-DD HH:MM:SS YYYY-MM-DD HH:MM:SS.SSS YYYY-MM-DDTHH:MM YYYY-MM-DDTHH:MM:SS YYYY-MM-DDTHH:MM:SS.SSS HH:MM HH:MM:SS HH:MM:SS.SSS  Examples\nSELECT DATE('now')\t# compute current date SELECT STRFTIME('%Y %m %d', 'now') SELECT Birthdate, STRFTIME('%Y', Birthdate) AS Year, STRFTIME('%m', Birthdate) AS Month, STRFTIME('%d', Birthdate) AS Day, DATE(('now') - Birthdate) AS Age FROM employees  Case statements A case statement mimics if-else statement found in most programming languages. It can be used in SELECT, INSERT, UPDATE, and DELETE statements.\nCASE [input_var_name] WHEN C1 THEN E1 WHEN C2 THEN E2 ... [ELSE else_result] END new_var_name  Example\nSELECT studentid, firstname, lastname, score, CASE WHEN score \u0026gt;= 60 THEN 'pass' WHEN score \u0026lt; 60 THEN 'fail' ELSE 'other' END score_category FROM exam_result  Views A view is essentially a stored query. It will be removed after database connect has ended.\nBenefits:\n It can add or remove columns without changing the schema.\n It provides a simpler option to creating a new table.\n It helps us clean up our queries and simplify the queries when we have to write\n It can be used to encapsulate complex queries or calculations that you are trying to write.\n  CREATE [TEMP] VIEW [IF NOT EXISTS] view_name AS SELECT \u0026lt;list of column names\u0026gt; FROM datatable # To see the view SELECT * FROM view_name # Remove the view DROP VIEW view_name  ","date":1563062400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563062400,"objectID":"8418315632886ab373a43dfc0fbdfed5","permalink":"/post/2019-07-14-sql/","publishdate":"2019-07-14T00:00:00Z","relpermalink":"/post/2019-07-14-sql/","section":"post","summary":"Introduction Structured Query Language (SQL) is a standard computer language for relational database management and data manipulation. It can be used to read, write, and update data. For data scientists, it is mainly used for data retrieval. There are several relational database management systems, such as Oracle, MySQL, and SQLite. Depending on the system you are using, the SQL syntax may be a little bit different.\nRetrieve data Use SELECT statement to query database, filtered by some conditions (optional).","tags":["sql"],"title":"SQL notes","type":"post"},{"authors":null,"categories":["programming"],"content":" Classes and objects In Scala, a class is a blueprint for objects. Once you define a class, you can create objects from the class blueprint with the keyword new. Through the object you can use all functionalities of the defined class.\nAn object is a named instance with members such as fields and methods. It is a class that has exactly one instance. There are three uses of objects.\n Contain fields and methods that are independent of any environment;  object Math { def divide(x: Int, y: Int) = x / y def square(x: Int) = x*x } println(Math.square(3)) println(Math square 3) // works if there is only one augment  Create instances of classes with the keyword new;  class Circle(radius: Double) { def area: Double = calculateArea(radius) } object Circle { private def calculateArea(radius: Double): Double = Pi * pow(radius, 2.0) } val circle1 = new Circle(5.0) println(circle1.area) An object with the same name as a class is called a companion object. Conversely, the class is the object’s companion class. A companion class or object can access the private members of its companion. Use a companion object for methods and values which are not specific to instances of the companion class.\n Create the entry point to a Scala program by defining a main method with a specific signature.  object \u0026lt;object name\u0026gt; { def main(args: \u0026lt;arg type\u0026gt;) = { } } class User(var name: String, var age: Int); object Demo { def main(args: Array[String]) { var user = new User(\u0026quot;Max\u0026quot;, 28); println(user.name); println(user.age); user.name = \u0026quot;Tom\u0026quot;; // rewritable because name is var user.age = 23; println(user.name); println(user.age); } } // Getter? Setter? // ------- ------- --------- // var yes yes // val yes no // default no no // you cannot access name outside the class if it\u0026#39;s private class User2(private var name: String, var age: Int) { def printName{ println(name) } }; var user2 = new User2(\u0026quot;Max\u0026quot;, 28); println(user2.name); // returns error // to access name inside a class user2.printName  Class Hierarchies Auxiliary constructor An alternative constructor for a class.\nWith primary constructors, you must have different signatures for your auxiliary constructors; you must call previously defined constructors in your auxiliary constructors.\nclass User(val name: String, var age: Int) { // primary constructor def this() { // auxiliary constructor this(\u0026quot;Tim\u0026quot;, 21); } def this(name: String) { this(name, 32); } } object Demo{ def main(args: Array[String]) { var user1 = new User(\u0026quot;Max\u0026quot;, 28); var user2 = new User(); var user3 = new User(\u0026quot;Max\u0026quot;); } }  Class inheritance: extending a class Scala doesn’t allow multiple inheritance from more than one class.\nA super class Polygon:\npackage Inheritance class Polygon { def area: Double = 0.0; } object Polygon { def main(args: Array[String]) { var poly = new Polygon; printArea(poly); var rect = new Rectangle(55.2, 20.0); printArea(rect); var tri = new Triangle(55.2, 20.0); printArea(tri); } def printArea(p: Polygon) { println(p.area); } } A subclass Rectangle:\npackage Inheritance class Rectangle(var width: Double, var height: Double) extends Polygon { override def area: Double = width * height; } A subclass Triangle:\npackage Inheritance class Triangle(var width: Double, var height: Double) extends Polygon { override def area: Double = width * height / 2; } override redefines an existing, non-abstract definition in a subclass.\n Abstract class An abstract class can contain members which are missing an implementation. Consequently, it cannot be instantiated with the operator new.\nAn abstract class does a few things for the inheriting subclass:\n define methods which can be used by the inheriting subclass; define abstract methods which the inheriting subclass must implement, in another word, it makes sure that we must implement methods inside subclasses; provide a common interface which allows the subclass to be interchanged with all other subclasses i.e. inheritance.  package Inheritance abstract class Polygon { def area: Double; // doesn\u0026#39;t provide any body to this method } object Polygon { def main(args: Array[String]) { // var poly = new Polygon; // cannot be instantiated // printArea(poly); var rect = new Rectangle(55.2, 20.0); printArea(rect); var tri = new Triangle(55.2, 20.0); printArea(tri); } def printArea(p: Polygon) { println(p.area); } }  Trait Scala doesn’t allow multiple inheritance and instead they use interface. A trait is a partially created interface.\npackage Inheritance trait Shape { def shape: String; } class Rectangle(var width: Double, var height: Double) extends Polygon with Shape { override def area: Double = height * width; def shape: String = \u0026quot;rectangle\u0026quot;; // can remove override when inheriting from a trait }   ","date":1561420800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561420800,"objectID":"9e18c535d7689bb8f25dd51c03e2f288","permalink":"/post/2019-06-25-scala3/","publishdate":"2019-06-25T00:00:00Z","relpermalink":"/post/2019-06-25-scala3/","section":"post","summary":"Classes and objects In Scala, a class is a blueprint for objects. Once you define a class, you can create objects from the class blueprint with the keyword new. Through the object you can use all functionalities of the defined class.\nAn object is a named instance with members such as fields and methods. It is a class that has exactly one instance. There are three uses of objects.","tags":["scala","big-data"],"title":"Scala notes III -- Classes and Objects","type":"post"},{"authors":null,"categories":["programming"],"content":" Function Syntax Scala is a functional programming language, which means that functions are first-class citizens and you can pass them around as parameters or values.\ndef add(x: Int, y: Int): Int = { return x + y; } println(add(21, 19)); // Other variants def multiply(x: Int, y: Int): Int = x * y // simplified version def divide(x: Int, y: Int) = x / y // can ignore the output type if it\u0026#39;s obvious def substract(x: Int = 10, y: Int = 2) = x - y // set default values You can define the function names as operator, e.g. +, *, /, -\ndef +(x: Int, y: Int) = x + y Partially applied functions val sum = (a: Int, b: Int, c: Int) =\u0026gt; a+b+c val f = sum(10, 20, _:Int) println(f(100)) // returns 130 import java.util.Date def log(date: Date, message: String) = { println(date + \u0026quot; \u0026quot; + message); } val date = new Date; val newLog = log(date, _ :String); newLog(\u0026quot;The message 1.\u0026quot;) newLog(\u0026quot;The message 2.\u0026quot;)  Closures A closure is a function which uses one or more variables declared outside this function.\nvar number = 10; //Example 1 val add = (x:Int) =\u0026gt; x + number; println(add(20)) number = 100 println(add(20)) // If the value of the variable changes, the result changes too. //Example 2 val add2 = (x:Int) =\u0026gt; { number = x+number; number } println(add2(20)) println(number) // numbder is 120 now //Example 3 val number = 10; // The result won\u0026#39;t change since number is fixed.  Blocks and Lexical Scope We can write nested functions in blocks to avoid name-space pollution. A block is delimited by braces { … } and it contains a sequence of definitions or expressions. The definitions inside a block are only visible from within the block. The definitions inside a block shadow definitions of the same names outside the block.\nval x = 0 def f(y: Int) = y + 1 val result = { val x = f(3) // x = 4, f() is visible inside the block x * x // 16, x shadows the x outside the block } + x // + 0 // return 16  Recursive functions Example:\ndef factorial(n: Int): Int = if (n == 0) 1 else n * factorial(n - 1) This function has a buildup of intermediate results that we have to keep until we can compute the final value so it is not a tail recursive function.\nTail Recursion\nIf a function calls itself as its last action, the function’s stack frame can be reused. This is called tail recursion. In general, if the last action of a function consists of calling a function (which may be the same), one stack frame would be sufficient for both functions. Such calls are called tail-calls.\nOne can require that a function is tail-recursive using a @tailrec annotation. If the annotation is given and the implementation of a function is not tail recursive, an error would be issued.\nExample:\n@tailrec def factorial(n: Int): Int = { def loop(acc: Int, n: Int): Int = if (n == 0) acc else loop(acc * n, n-1) loop(1, n) } The interest of tail recursion is mostly to avoid very deep recursive chains. If your input data are such that deep recursive chains could happen, then it’s a good idea to reformulate your function to be tail recursive, to run in constant stack frame, so as to avoid stack overflow exceptions.\nOn the other hand, if your input data are not susceptible to deep recursive chains then write your function the clearest way you can, which often is not tail recursive, and don’t worry about the stack frames that are spent. For example, the tail recursive function of factorial above grows very quickly even after very low number of recursive steps. So it is not worth making factorial a tail recursive function.\n  Higher-order functions An important concept in functional programming is called higher-order function. It lets you pass functions as arguments and return them as results. For example,\ndef sum(a: Int, b: Int, f: Int =\u0026gt; Int): Int = { if(a \u0026gt; b) 0 else f(a) + sum(a+1, b, f) } def sumInts(a: Int, b: Int) = sum(a, b, x =\u0026gt; x); def sumCubes(a: Int, b: Int) = sum(a, b, x =\u0026gt; x * x * x)  The Int =\u0026gt; Int is a function type that maps Int to Int.\n The x =\u0026gt; x and x =\u0026gt; x * x * x are anonymous functions (aka function literals) that do not contain function names. Instead of defining a function cube, for example\ndef cube(x: Int): Int = x * x * x the anonymous function x =\u0026gt; x * x * x provides a lightweight function definition and is useful when we want to create an inline function. More examples of anonymous functions:\n(x, y) =\u0026gt; _+_ // i.e. (x, y) =\u0026gt; x+y (x, y) =\u0026gt; _min _ // i.e. (x, y) =\u0026gt; x min y (x, y) =\u0026gt; _max _ // i.e. (x, y) =\u0026gt; x max y // Anonymous functions with parameters var add = (x: Int, y: Int) =\u0026gt; x + y // Anonymous functions without parameters var word = () =\u0026gt; {\u0026quot;Hello world.\u0026quot;}  Currying Currying is a special form of higher-order function. It can transform a function that takes multiple parameters into a function that consists of (nested) anonymous functions with each taking one parameter. (arg2 = ...(agrn = E))`. **Multiple parameter lists** A simple example would be ```scala def add(x: Int) = (y: Int) = x + y; println(add(20)(10)); // You can also apply partial applied function in currying val sum40 = add(40); println(sum40(100)); //Simpler version in scala def add2 (x: Int) (y: Int) = x + y; val sum50 = add2(50)_; //have to add _ println(sum50(10)) ``` --\nFor example, we can rewrite the sum function which takes three parameters (a, b, f) to a function that returns a function\ndef sum(f: Int =\u0026gt; Int): (Int, Int) =\u0026gt; Int = { def sumF(a: Int, b: Int): Int = if(a \u0026gt; b) 0 else f(a) + sumF(a+1, b) sumF } def sumInts = sum(x =\u0026gt; x); def sumCubes = sum(x =\u0026gt; x * x * x) println( sumCubes(1, 3) ) Here the sum function takes one argument f and returns a function sumF of type (Int, Int) =\u0026gt; Int. This allows us to get rid of those parameters a and b in sumInts and sumCubes. We can also avoid defining sumInts and sumCubes by applying sum to a function directly, for example, sum(cube)(1, 3) is equivalent to sumCubes(1, 3).\nIn Scala, functions that return functions are so useful that there is a special syntax for them. For example, the sum function with the nested sumF function can be simplified as\ndef sum(f: Int =\u0026gt; Int)(a: Int, b: Int): Int = { if(a \u0026gt; b) 0 else f(a) + sum(f)(a+1, b) } The function type of sum is (Int =\u0026gt; Int) =\u0026gt; (Int, Int) =\u0026gt; Int or (Int =\u0026gt; Int) =\u0026gt; ( (Int, Int) =\u0026gt; Int )\n  ","date":1558828800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558828800,"objectID":"6f7e6c92ac606996ef497eb7f3a984cb","permalink":"/post/2019-05-26-scala2/","publishdate":"2019-05-26T00:00:00Z","relpermalink":"/post/2019-05-26-scala2/","section":"post","summary":"Function Syntax Scala is a functional programming language, which means that functions are first-class citizens and you can pass them around as parameters or values.\ndef add(x: Int, y: Int): Int = { return x + y; } println(add(21, 19)); // Other variants def multiply(x: Int, y: Int): Int = x * y // simplified version def divide(x: Int, y: Int) = x / y // can ignore the output type if it\u0026#39;s obvious def substract(x: Int = 10, y: Int = 2) = x - y // set default values You can define the function names as operator, e.","tags":["scala","big-data"],"title":"Scala notes II -- Functions","type":"post"},{"authors":null,"categories":["programming"],"content":" Data types Boolean true or false Byte 8 bit signed value Short 16 bit signed value Char 16 bit unsigned Unicode character Int 32 bit signed value Long 64 bit signed value Float 32 bit IEEE 754 single-precision float Double 64 bit IEEE 754 double-precision float String A sequence of characters Unit Corresponds to no value Null null or empty references Nothing subtype of every other type; includes no ... Any The supertype of any type; any object is of .. AnyRef The supertype of any reference type More on datatype: https://www.tutorialspoint.com/scala/scala_data_types.htm\n Variables  // mutable variable: variable value can be changed var myVar : String = \u0026quot;Foo\u0026quot; // imutable variable: variable value cannot be changed val myVar : Int = 10 // Note: scala will detect the data types by the initial values. val x = {val a: Int = 200; val b: Int = 300; a+b} // this value is not assigned until x is used (you are only using memory in demand) lazy val x = 500  String  String interpolation val name = \u0026quot;mark\u0026quot; val age = 18 println(name + \u0026quot; is\u0026quot; + age + \u0026quot; year old.\u0026quot;) println(s\u0026quot;$name is $age years old.\u0026quot;) println(f\u0026quot;$name%s is $age%d years old.\u0026quot;) //typesafe: %s specifies string type and %d specifies double type // mark is 18 years old. println(raw\u0026quot;Hello \\nworld.\u0026quot;) // Hello \\nworld. println(s\u0026quot;Hello \\nworld.\u0026quot;) // Hello // world.  Methods for Strings val str1: String = \u0026quot;Hello world\u0026quot;; val str2: String = \u0026quot; Max\u0026quot;; // calculate length println(str1.length()) // returns 11 // concatenate println(str1.concat(str2)) // returns \u0026quot;Hellow world Max\u0026quot; println(str1 + str2) // formating val num1 = 75; val num2 = 100.25; val result = printf(\u0026quot;(%d -- %f -- %s)\u0026quot;, num1, num2, str1); println(result); println(\u0026quot;(%d -- %f -- %s)\u0026quot;.format(num1, num2, str1));   Arrays An array is a data structure which can store fixed-sized sequential elements of same data type.\nval myarray: Array[Int] = new Array[Int](4); // index starts from 0 in Scala myarray(0) = 20; myarray(1) = 50; myarray(2) = 10; myarray(3) = 10; // println(myarray) // won\u0026#39;t work for(x \u0026lt;- myarray){ println(x); } // Default values of an array val myarray2 = new Array[Int](5); // default value is 0 val myarray2 = new Array[String](5); // default value is null val myarray2 = new Array[Double](5); // default value is 0.0 val myarray2 = new Array[Boolean](5); // default value is false // concatenate import Array._ val myarray3 = Array(1, 2, 3, 5, 8); println(myarray3.length) val result = concat(myarray3, myarray3); for(x \u0026lt;- result){ println(x) }  Collections Lists Lists are immutable and represent the link lists whereas arrays are mutable and flat.\nval mylist: List[Int] = List(1, 2, 5, 8); val names: List[String] = List(\u0026quot;Max\u0026quot;, \u0026quot;Tom\u0026quot;, \u0026quot;John\u0026quot;) println(mylist) println(names) println(mylist(0)) //mylist(0) = 5 // cannot change the value of a list println(0 :: mylist) // prepend 0 but won\u0026#39;t change mylist println(Nil) // create a empty list println(1 :: 5 :: 9 :: Nil) // create a list println(List.fill(5)(2)) // returns List(2, 2, 2, 2, 2) println(mylist.head) println(names.tail) // print everything except for the first element println(names.isEmpty) println(mylist.reverse) println(mylist.max) // iterate over each element and run the given function mylist.foreach( println ) var sum: Int = 0; mylist.foreach( sum += _) println(sum) // sum up all the elements  Sets A set is a collection of different elements of CM data types. So a set cannot have duplicated values inside them.\nval myset: Set[Int] = Set(1, 2, 2, 5) println(myset) // returns Set(1, 2, 5) By default, set is immutable in Scala. If we need to declare a mutable set, we can use scala.collection.mutable.Set instead.\nval myset2 = scala.collection.mutable.Set(1, 3, 5) println(myset2) To add a value into the set\nprintln(myset + 10) println(myset) // myset is not changed because it\u0026#39;s immutable Set is not ordered, which means the new element is assigned to a random location and you cannot index an element.\nprintln(myset(8)) // check if 8 exists in myset or not Other useful functions in set:\nprintln(myset.head) println(myset.tail) println(myset.isEmpty) // concatenate two sets println(myset ++ myset2) println(myset.++(myset2)) // find intersection of two sets println(myset.\u0026amp;(myset2)) println(myset.intersect(myset2)) // find min \u0026amp; max println(myset.min) println(myset.max) // for loop myset.foreach(println) for(x \u0026lt;- myset){ println(x) }  Maps A map is a collection of key-value pairs, for example 801-max, 802-tom, 804-july.\nval mymap : Map[Int, String] = Map(801 -\u0026gt; \u0026quot;max\u0026quot;, 802 -\u0026gt; \u0026quot;tom\u0026quot;, 804 -\u0026gt; \u0026quot;july\u0026quot;); println(mymap) println(mymap(802)) Duplication of keys is not possible in a map.\nval mymap : Map[Int, String] = Map(801 -\u0026gt; \u0026quot;max\u0026quot;, 802 -\u0026gt; \u0026quot;tom\u0026quot;, 804 -\u0026gt; \u0026quot;july\u0026quot;, 804 -\u0026gt; \u0026quot;jully\u0026quot;); println(mymap); // it takes the last entry of 804 println(mymap.keys) // returns a set println(mymap.values) println(mymap.isEmpty) println(mymap.contains(801000)) // check if a key (or exception case) is valid/exist in the map //for loop mymap.keys.foreach{ key =\u0026gt; println(\u0026quot;key \u0026quot; + key); println(\u0026quot;value \u0026quot; + mymap(key)); } //concatenate val mymap2 : Map[Int, String] = Map( 805 -\u0026gt; \u0026quot;lua\u0026quot;); println(mymap ++ mymap2);  Tuples A tuple is a class that can contain different kinds of elements, unlike array. A tuple is immutable in scala. You cannot change a tuple once it’s declared. A tuple can contain 22 elements at most.\nval mytuple = (1, 2, \u0026quot;hello\u0026quot;, true); println(mytuple); val mytuple2 = new Tuple3(1, 2, \u0026quot;hello\u0026quot;); // have to indicate the number of elements in a tuple right after the \u0026quot;Tuple\u0026quot; keyword; maximum number is 22. println(mytuple._3) // returns the third element val mytuple3 = new Tuple3(1, \u0026quot;hello\u0026quot;, (2,3)) println(mytuple3._3._2); // print 3 //for loop mytuple.productIterator.foreach{ i =\u0026gt; println(i) }  Options An option is a container which can give you two values (Some or None).\nval lst = List(1, 2, 3); val map = Map(1 -\u0026gt; \u0026quot;Tom\u0026quot;, 2 -\u0026gt; \u0026quot;Max\u0026quot;, 3 -\u0026gt; \u0026quot;John\u0026quot;); println(lst.find(_ \u0026gt; 6)); // return None println(lst.find(_ \u0026gt; 2)); // return Some(3) println(map.get(1)); // return Some(Tom) println(map.get(4)); // return None // to abstract the values println(lst.find(_ \u0026gt; 2).get); // return the element value 3 println(map.get(5).get); // get an exception error message // to avoid exception error message println(map.get(5).getOrElse(\u0026quot;No name found.\u0026quot;)); // to define options val opt : Option[Int] = None; println(opt.isEmpty); // returns true val opt2 : Option[Int] = Some(55); // returns false   Comment code Comment one line\n// println(\u0026quot;Hello\u0026quot;) Comment multiple lines\n/* println(\u0026quot;Hello\u0026quot;) println(\u0026quot;world\u0026quot;) */  Ifelse statement val x = 20 var res = \u0026quot;\u0026quot; if(x == 20){ res = \u0026quot;x==20\u0026quot; } else { res = \u0026quot;x!=20\u0026quot; } println(res) val res2 = if(x == 20) \u0026quot;x==20\u0026quot; else \u0026quot;x!=20\u0026quot; println(res2) println(if(x == 20) \u0026quot;x==20\u0026quot; else \u0026quot;x!=20\u0026quot;) Use \u0026amp;\u0026amp; for and and || for or.\n Match expressions val age: Int = 18 age match { case 18 =\u0026gt; println(\u0026quot;age 18\u0026quot;) case 20 =\u0026gt; println(\u0026quot;age 20\u0026quot;) case _ =\u0026gt; println(\u0026quot;default\u0026quot;) // catch default/unmatched case } // use as expression val result = age match { case 18 =\u0026gt; \u0026quot;age 18\u0026quot; case 20 =\u0026gt; \u0026quot;age 20\u0026quot; case _ =\u0026gt; \u0026quot;default\u0026quot; // catch default/unmatched case } println(\u0026quot;result = \u0026quot; + result) // mutiple expressions val i =8; i match { case 1|3|5|7|9 =\u0026gt; println(\u0026quot;odd\u0026quot;) case 2|4|6|8|10 =\u0026gt; println(\u0026quot;even\u0026quot;) }  Loops while loop check the condition before executing\nvar x = 0 while(x \u0026lt; 10){ println(\u0026quot;x = \u0026quot; + x) x += 1 // x = x + 1 }  do-while loop execute at least once regardless of the condition\nvar y = 0 do { println(\u0026quot;y = \u0026quot; + y) y += 1 } while (y \u0026lt; 0);  for loop for ( i \u0026lt;- 1 to 5){ println(\u0026quot;i using to \u0026quot; + i) } // identical for ( i \u0026lt;- 1 until 6){ println(\u0026quot;i using to \u0026quot; + i) } for ( i \u0026lt;- 1 to 5; j \u0026lt;- 1 to 3){ println(\u0026quot;i,j using to \u0026quot; + i + \u0026quot;,\u0026quot; + j) } val lst = List(1, 5, 3, 2, 8) for( i \u0026lt;- lst; if i \u0026lt; 3){ println(\u0026quot;i using to \u0026quot; + i) } // Use for loop as an expression val result = for { i \u0026lt;- lst; if i \u0026lt; 3 } yield { i * i } println(\u0026quot;result = \u0026quot; + result) // return a List   Map, flatten, and filter Map method\nval lst = List(1, 2, 3, 5, 7, 9, 10); val mymap = Map(1 -\u0026gt; \u0026quot;Tom\u0026quot;, 2 -\u0026gt; \u0026quot;Max\u0026quot;, 3 -\u0026gt; \u0026quot;John\u0026quot;); // double every element in lst println(lst.map(x =\u0026gt; x*2)) println(lst.map(_ *2)) println(mymap.mapValues(x =\u0026gt; \u0026quot;hi \u0026quot; + x)); // apply toUpper to every element in the string \u0026quot;hello\u0026quot; println(\u0026quot;hello\u0026quot;.map(_.toUpper)) Flatten method\n// flatten contents of a list of lists println(List(List(1, 2, 3), List(3, 4, 5)).flatten) println(lst.flatMap(x =\u0026gt; List(x, x+1)))  Filter method\n// abstract even numbers println(lst.filter(x =\u0026gt; x%2 == 0))  Reduce, fold, and scan (left/right) Reduce method\nval lst = List(1, 2, 3, 4, 6, 7, 8); val lst2 = List(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;, \u0026quot;C\u0026quot;); println(lst.reduceLeft(_ + _)) // returns sum of all elements println(lst2.reduceLeft(_ + _)) // returns \u0026quot;ABC\u0026quot; by (AB)C println(lst2.reduceRight(_ + _)) // returns \u0026quot;ABC\u0026quot; by A(BC) println(lst.reduceLeft((x, y) =\u0026gt; {println(x + \u0026quot;,\u0026quot;, + y); x+y;})) Fold method is similar to reduce method but can insert initial argument.\nprintln(lst.foldLeft(10)(_ + _)) // return 10 + sum(lst)  Scan method takes initial value and applies it to each element in reduce method. It returns the map of intermediate results.\nprintln(lst.scanLeft(10)(_ + _)) println(lst2.scanLeft(\u0026quot;z\u0026quot;)(_ + _))  Lazy evaluation Lazy evaluation is an evaluation strategy that delays the evaluation of an expression until it’s needed. Scala supports strict evaluation by default and lazy evaluation if specified.\nval e = 9; // strict evaluation lazy val l = 9; // lazy evaluation call-by-value v.s. call-by-name # call-by-value, the general case def method1(n: Int) { println(\u0026quot;Method 1\u0026quot;); println(n); } # call-by-name def method2(n: =\u0026gt; Int) { // use =\u0026gt; println(\u0026quot;Method 2\u0026quot;); println(n); } val add = (a: Int, b: Int) =\u0026gt; { println(\u0026quot;Add\u0026quot;); a + b } method1(add(5, 6)) // Add // Method 1 // 11 method2(add(5, 6)) // Method 2 // Add // 11   Scala in IntelliJ IDEA SBT tasks The following tasks can be run in sbt shell:\n Scala interpreter: type console to start and type  to quit\n Type compile to compile the source code located in the directory src/main/scala\n Type test to test the unit tests for the project located in src/test/scala\n If your project has an object with a main method (or an object extending the trait App), then you can run the code in sbt easily by typing run. In case sbt finds multiple main methods, it will ask you which one you’d like to execute.\n    Unit test package example import java.util.NoSuchElementException import org.scalatest.FunSuite import org.junit.runner.RunWith import org.scalatest.junit.JUnitRunner /** * This class implements a ScalaTest test suite for the methods in object * `Lists` that need to be implemented as part of this assignment. A test * suite is simply a collection of individual tests for some specific * component of a program. * * A test suite is created by defining a class which extends the type * `org.scalatest.FunSuite`. When running ScalaTest, it will automatically * find this class and execute all of its tests. * * Adding the `@RunWith` annotation enables the test suite to be executed * inside eclipse using the built-in JUnit test runner. * * You have two options for running this test suite: * * - Start the sbt console and run the \u0026quot;test\u0026quot; command * - Right-click this file in eclipse and chose \u0026quot;Run As\u0026quot; - \u0026quot;JUnit Test\u0026quot; */ @RunWith(classOf[JUnitRunner]) class ListsSuite extends FunSuite { // We fist import all members of the `List` object. import Lists._ test(\u0026quot;sum of a few numbers\u0026quot;) { assert(sum(List(1,2,0)) === 3) assert(sum(List(-2, -1, -5)) === -8) assert(sum(List(0, 0, 0)) === 0) assert(sum(List()) === 0) } test(\u0026quot;max of a few numbers\u0026quot;) { assert(max(List(3, 7, 2)) === 7) assert(max(List(-3, -7, -2)) === -2) assert(max(List(2, 2, 2)) === 2) assert(max(List(-3, 0, 3, -5)) === 3) intercept[NoSuchElementException]{ max(List()) } } }  Useful links   Youtube tutorial\n Coursera: Functional Programming Principles in Scala\n Coursera: Big Data Analysis with Scala and Spark\n Document tutorial\n ScalaFiddle\n   ","date":1558137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558137600,"objectID":"5e528f48110b1096b704e4599defe3c4","permalink":"/post/2019-05-18-scala1/","publishdate":"2019-05-18T00:00:00Z","relpermalink":"/post/2019-05-18-scala1/","section":"post","summary":"Data types Boolean true or false Byte 8 bit signed value Short 16 bit signed value Char 16 bit unsigned Unicode character Int 32 bit signed value Long 64 bit signed value Float 32 bit IEEE 754 single-precision float Double 64 bit IEEE 754 double-precision float String A sequence of characters Unit Corresponds to no value Null null or empty references Nothing subtype of every other type; includes no .","tags":["scala","big-data"],"title":"Scala notes I","type":"post"},{"authors":null,"categories":["programming"],"content":" Configuration Set up global configuration variables if you haven\u0026rsquo;t done so\n$ git config --global user.name \u0026quot;\u0026lt;name\u0026gt;\u0026quot; $ git config --global user.email \u0026quot;\u0026lt;email\u0026gt;\u0026quot;  Git should automatically do a rebase when you do a pull, which is what you want\n$ git config branch.autosetuprebase always  To set up configuration for DiffMerge, follow the guide http://coding4streetcred.com/blog/post/configure-diffmerge-for-your-git-difftool.\nLocal Usage of Git Staging Check if there is any unstaged or untracked files\n$ git status  Add files to the staging\n$ git add \u0026lt;file.name\u0026gt; // add a specific file $ git add . // add all files from the current folder $ git add myfolder/ // add all files from the subfolder 'myfolder' $ git add (-A) // add all files from entire working tree, even from upper directory $ git add --no-all myfolder/ // add all but deleted files from myfolder: `` $ git add -u or --update // add all but new or untracked files  Remove files from the staging\n$ git reset HEAD \u0026lt;file.name\u0026gt; // remove a specific file $ git reset // remove everything from the staging area  Reset\n$ git checkout -- \u0026lt;filename\u0026gt; // discard the changes in a file $ git reset --soft HEAD~1 // leave all your changed files \u0026quot;Changes to be committed\u0026quot;, as git status would put it $ git reset --soft \u0026lt;commit hash\u0026gt; // move back to staging dir and keep the modification $ git reset \u0026lt;commit hash\u0026gt; // move back to working dir and keep the modification $ git reset --hard \u0026lt;commit hash\u0026gt; // revert tracked files back before modification  $ git clean -df // get rid of any untracked dir and files $ git reflog // lifesaver if you accidently delete something important $ git revert \u0026lt;hash\u0026gt; // ?  Commit Commit changes\n$ git commit -m \u0026quot;\u0026lt;messages\u0026gt;\u0026quot; // commit with a message created $ git commit --amend -m \u0026quot;\u0026lt;new messages\u0026gt;\u0026quot; // edit the commit message $ git commit --amend // commit changes to the previous commit  Show commit history\n$ git log  How to write a great Git commit message  Separate subject from body with a blank line Limit the subject line to 50 characters Capitalize the subject line Do not end the subject line with a period Use the imperative mood in the subject line Wrap the body at 72 characters Use the body to explain what and why vs. how  Edit a specific commit $ git rebase -i @~3 # Show the last 3 commits in a text editor  Find the commit you want, change pick to e (edit), and save and close the file. Git will rewind to that commit, allowing you to either:\n use $ git commit --amend to make changes, or\n use $ git reset @~ to discard the last commit, but not the changes to the files (i.e. take you to the point you were at when you\u0026rsquo;d edited the files, but hadn\u0026rsquo;t committed yet).\n  Then run $ git rebase --continue and Git will replay the subsequent changes on top of your modified commit. You may be asked to fix some merge conflicts. Note: @ is shorthand for HEAD, and ~ is the commit before the specified commit.\nOther approaches: https://stackoverflow.com/questions/1186535/how-to-modify-a-specified-commit-in-git\nSquash several commits into one Step 1: Invoke git to start an interactive rebase session:\n$ git rebase -i HEAD~[N]\nwhere N is the number of commits you want to join, starting from the most resent one. For example $ git rebase -i HEAD~3.\nOR if you have too many commits to count, try\n$ git rebase -i [commit-hash]\nwhere [commit-hash] is the hash of the commit just before the first one you want to rewrite from. For example, $ git rebase -i 5392bc to join the top 3 commits in below\nfdascc Fix at 13:00 asfdsd Fix at 12:00 kgfdas Fix at 11:00 5392bc Fix at 10:00  Step 2: Picking and squashing\nAt this point your editor of choice will pop up, showing the list of commits you want to merge in a reverse order. For example,\npick kgfdas Fix at 11:00 pick asfdsd Fix at 12:00 pick fdascc Fix at 13:00  Our task here is to mark all the commits as squashable, except the first/older one: it will be used as a starting point. You mark a commit as squashable by changing the work pick into squash next to it (or s for brevity, as stated in the comments). The result would be:\npick kgfdas Fix at 11:00 s asfdsd Fix at 12:00 s fdascc Fix at 13:00  Save the file and close the editor.\nStep 3: Create the new commit\nYou have just told Git to combine all three commits into the the first commit in the list. It\u0026rsquo;s now time to give it a name: your editor pops up again with a default message, made of the names of all the commits you have squashed.\nYou can leave it as it is and the commit message will result in a list of all the intermediate commits, or wipe out the default message and use something more self-explanatory.\nBranch You can edit and commit under a branch which wont affect the master branch at all\n$ git branch // check which branch you are currently in (with *) $ git branch \u0026lt;branch_name\u0026gt; // create a branch $ git checkout \u0026lt;branch_name\u0026gt; // switch to the selected branch  $ git cherry-pick \u0026lt;commit hash\u0026gt; # bring the commit to the current branch  Merge Branch\n$ git checkout master $ git merge \u0026lt;branch_name\u0026gt; $ git branch --merged // check if it's merged successfully  Delete a branch\n$ git branch -d \u0026lt;branch_name\u0026gt; // delete branch locally $ git push origin --delete \u0026lt;branch_name\u0026gt; // delete branch remotely  Stash You can save changes in a temporary place so you can work on other things and come back later. Note that stash won\u0026rsquo;t create anything to commit.\n$ git stash save \u0026quot;\u0026lt;message\u0026gt;\u0026quot; // save changes in stash $ git stash list // check existing stash $ git stash apply \u0026lt;stash name\u0026gt; // fetch the changes in the stash $ git stash pop // apply changes in the top stash (the newest) and drop it from the stash list $ git stash drop \u0026lt;stash name\u0026gt; // drop the selected stash $ git stash clear // remove all the changes made  Visual Tool DiffMerge\n$ git difftool $ git mergetool  Gitk\n$ gitk  Others Check changes made in the code:\n$ git diff \u0026lt;old hash\u0026gt; \u0026lt;new hash\u0026gt;  Create an ignore file:\n$ touch .gitignore  The .gitignore file is a text file that list the files you want to ignore for tracking.\nRemote Usage of Git Clone a project:\n$ git clone \u0026lt;url\u0026gt; \u0026lt;where to clone\u0026gt; $ git clone \u0026lt;url\u0026gt; . // clone to current directory  View info about the remote repository:\n$ git remote -v // list repository info $ git branch -a // list all the branches, localy and remotely  Pull from the remote repository\n$ git pull origin master  Push changes to the remote repository after making local commitments:\n$ git push origin master // push to Git $ git push origin HEAD:refs/for/master // push to Gerrit  Push branch to the remote repository\n$ git push -u origin \u0026lt;branch_name\u0026gt; // -u is used so in future you can just simply use $git pull and $git push  References Git Development workflow: https://wcdma-confluence.rnd.ki.sw.ericsson.se/display/TAE/WMR+GIT+Development+workflow\nGit Basic Commands: https://wcdma-confluence.rnd.ki.sw.ericsson.se/display/TAE/Git+Basic+Commands\nGit Gerrit: https://wcdma-confluence.rnd.ki.sw.ericsson.se/display/TAE/Git+Gerrit\nMore:\nhttps://git-scm.com/docs\nhttps://gerrit-review.googlesource.com/Documentation/intro-user.html#gerrit\n","date":1555372800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555372800,"objectID":"8e6b496080d072a5968df1dac6b563f4","permalink":"/post/git-commands/","publishdate":"2019-04-16T00:00:00Z","relpermalink":"/post/git-commands/","section":"post","summary":"Configuration Set up global configuration variables if you haven\u0026rsquo;t done so\n$ git config --global user.name \u0026quot;\u0026lt;name\u0026gt;\u0026quot; $ git config --global user.email \u0026quot;\u0026lt;email\u0026gt;\u0026quot;  Git should automatically do a rebase when you do a pull, which is what you want\n$ git config branch.autosetuprebase always  To set up configuration for DiffMerge, follow the guide http://coding4streetcred.com/blog/post/configure-diffmerge-for-your-git-difftool.\nLocal Usage of Git Staging Check if there is any unstaged or untracked files","tags":["git"],"title":"Git commands","type":"post"},{"authors":null,"categories":["programming"],"content":" Introduction The R programming language, along with RStudio, has become one of the most popular tools for data analysis as it contains a large amount of open-source packages developed by a community of statisticians. However, R or RStudio is not ideal for Big Data analysis as mostly the data would not fit into R memory. On the other hand, Spark has become the leading platform for big-data analytics. It works with the system to distribute data across clusters and process data in parallel. Moreover it provides native bindings for different languages such as Java, Python, Scala, and R.\nsparklyr is an R package that allows us to analyze data in Spark from R. It supports dplyr, a popular tool for working with data frame like objects both in memory and out of memory, and many machine learning algorithms to run classifiers, regressions, and so on in Spark. It is extensible that you can create R packages that depend on sparklyr to call the full Spark API, such as H2O’s rsparkling, an R package that works with H2O’s machine learning algorithm. With sparklyr and rsparkling, we have access to all the tools in H2O for analysis with R and Spark.\n Connect to Spark Suppose that sparklyr has been successfully installed in your R environment. To get start with Spark using sparklyr and a local cluster,\nlibrary(sparklyr) spark_install() sc \u0026lt;- spark_connect(master = \u0026quot;local\u0026quot;) or if a Spark cluster has been made available to you\nsc \u0026lt;- spark_connect(master = \u0026quot;\u0026lt;cluster-master\u0026gt;\u0026quot;) When I run spark_connect(master = \u0026quot;local\u0026quot;), I got the error message\n\u0026quot;Java 9 is currently unsupported in Spark distributions unless you manually install Hadoop 2.8 and manually configure Spark. Please consider uninstalling Java 9 and reinstalling Java 8. To override this failure set \u0026#39;options(sparklyr.java9 = TRUE)\u0026#39;.\u0026quot; That’s because on my Windows 10 laptop, my JAVA_HOME was set to C:\\Java\\jdk, which has Version 11, in the system environment. I change it to\nJAVA_HOME = \u0026quot;C:\\Java\\jre1.8.0_151\u0026quot; Note that my Java folder was in C:\\Program Files (x86)\\.. and it created an issue when connecting to Spark. So I moved the folder directly to C:\\.. to solve the problem. Howoever, another error triggers when connecting to Spark\n---- Output Log ---- Error occurred during initialization of VM Could not reserve enough space for 2097152KB object heap It cannot allocate 2GB and this seems a common issue under Windows with a Java version using x86. To solve this, we can either install java x64 or reduce the default memory\nconfig \u0026lt;- spark_config() config[[\u0026quot;sparklyr.shell.driver-memory\u0026quot;]] \u0026lt;- \u0026quot;512m\u0026quot; sc \u0026lt;- spark_connect(master = \u0026quot;local\u0026quot;, config = config) Finally, I get connected to Spark! Now I can run analyses and build models using Spark from R.\nTo monitor and analyze execution, we can go to the Spark’s web interface:\nspark_web(sc) Once we are done with analysis, we can disconnect spark,\nspark_disconnect(sc)  Data Analysis Copy data to Spark The data set mtcars is a dataframe available in R. Run ?mtcars to see more details. To copy the data set into Apache Spark\ncars \u0026lt;- copy_to(sc, mtcars) # or cars \u0026lt;- sdf_copy_to(sc, mtcars) Now we can access the data that was copied into Spark from R using the cars reference.\nTo read data from existing data sources in csv format and copy to Spark,\ncars \u0026lt;- spark_read_csv(sc, \u0026quot;cars.csv\u0026quot;) To export data as a csv file,\nspark_write_csv(cars, \u0026quot;cars.csv\u0026quot;) Other formats like plain text, JSON, JDBC are supported as well.\n Exploratory data analysis When using Spark from R to analyze data, most regular R functions, such as nrow, won’t work directly on the Spark reference cars. Instead, we can either use SQL through the DBI package or use dplyr (strongly preferred). Most of the data transformation made available by dplyr to work with local data frames are also available to use with a Spark connection. This means that a general approach to learning dplyr can be taken in order to gain more proficiency with data exploration and preparation with Spark. For example, to count how many records are available in cars,\ndplyr::count(cars) # = nrow(mtcars) To select columns, sample rows, and collect data from Spark,\ndf_in_r \u0026lt;- dplyr::select(cars, hp, mpg) %\u0026gt;% dplyr::sample_n(100) %\u0026gt;% dplyr::collect() Then we can apply regular R functions on the dataframe df_in_r, for example\ndim(df_in_r) plot(df_in_r) If a particular functionality is not available in Spark and no extension has been developed, we can distribute the R code across the Spark cluster. For example,\ncars %\u0026gt;% spark_apply(nrow) This is a powerful tools but comes with additional complexity that we should only use as a last resort option. We should learn how to do proper data analysis and modeling without having to distribute custom R code across our cluster!\nThe corrr package specializes in correlations. It contains friendly functions to prepare and visualize the results.\nlibrary(corrr) cars %\u0026gt;% correlate(use = \u0026quot;pairwise.complete.obs\u0026quot;, method = \u0026quot;pearson\u0026quot;) %\u0026gt;% shave() %\u0026gt;% rplot() The sparklyr package also provides some functions for data transformation and exploratory data analysis. Those functions usually have sdf_ as a prefix.\n Modeling Spark MLlib is the component of Spark that allows one to write high level code to perform machine learning tasks on distributed data. Sparklyr provides an interface to the ML algorithms that should be familiar to R users. For example, you can run a linear regression as follows:\nmodel \u0026lt;- ml_linear_regression(cars, mpg ~ hp) model %\u0026gt;% ml_predict(copy_to(sc, data.frame(hp = 250 + 10 * 1:10))) %\u0026gt;% transmute(hp = hp, mpg = prediction) %\u0026gt;% full_join(select(cars, hp, mpg)) %\u0026gt;% collect() %\u0026gt;% plot() To retrieve additional statistics from the model,\nbroom::glance(model) Spark provides a wide range of algorithms and feature transformers. Those functions usually have ml_ or ft_ as prefix.\n Extensions Many extensions to sparklyr have been made available, such as sparklyr.nested, rsparkling, and Mleap. The sparklyr.nested package helps you manage values that contain nested information, for example JSON files. The Mleap enables Spark pipelines in production. The rsparkling package provides H2O support. For example, you may convert a Spark dataframe to an H2O frame and then use h2o package to run basic H2O commands in R.\nh2o_df \u0026lt;- rsparkling::as_h2o_frame(sc, cars) model \u0026lt;- h2o::h2o.glm(x = \u0026quot;gp\u0026quot;, y = \u0026quot;mpg\u0026quot;, h2o_df, alpha = 0, lambda = 0) summary(model) You can use the invoke family of functions to generate the objects you want and write extension function that calls functions in Java or Scala. For example,\ncount_lines \u0026lt;- function(sc, \u0026quot;file\u0026quot;) { spark_context(sc) %\u0026gt;% invoke(\u0026quot;textFile\u0026quot;, file, 1L) %\u0026gt;% invoke(\u0026quot;count\u0026quot;) } The count_lines function calls the textFile().count() method in Java [2].\n  References [1] The R in Spark: Learning Apache Spark with R. https://therinspark.com/starting.html#starting-spark-web-interface.\n[2] Sparklyr from Rstudio. https://spark.rstudio.com/extensions/.\n ","date":1554854400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554854400,"objectID":"45f1a30cfc777dba3ed80fea62e2bba4","permalink":"/post/2019-04-10-sparklyr/","publishdate":"2019-04-10T00:00:00Z","relpermalink":"/post/2019-04-10-sparklyr/","section":"post","summary":"Introduction The R programming language, along with RStudio, has become one of the most popular tools for data analysis as it contains a large amount of open-source packages developed by a community of statisticians. However, R or RStudio is not ideal for Big Data analysis as mostly the data would not fit into R memory. On the other hand, Spark has become the leading platform for big-data analytics. It works with the system to distribute data across clusters and process data in parallel.","tags":["spark","big-data"],"title":"sparklyr (Spark in R)","type":"post"},{"authors":null,"categories":["statistics"],"content":" Introduction The ARIMA (autoregressive integrated moving average) models are also known as Box–Jenkins models. ARIMA models are applied in some cases where data show evidence of non-stationarity, where an initial differencing step (corresponding to the “integrated” part of the model) can be applied one or more times to eliminate the non-stationarity.\nThe AR part of ARIMA indicates that the evolving variable of interest is regressed on its own lagged (i.e., prior) values. The MA part indicates that the regression error is actually a linear combination of error terms whose values occurred contemporaneously and at various times in the past. The I (for “integrated”) indicates that the data values have been replaced with the difference between their values and the previous values (and this differencing process may have been performed more than once).\nWhen two out of the three model parameters are zeros, the model may be referred to based on the non-zero parameter, dropping “AR”, “I” or “MA” from the acronym describing the model. For example, \\(ARIMA (1,0,0)\\) is \\(AR(1)\\), \\(ARIMA(0,1,0)\\) is \\(I(1)\\), and \\(ARIMA(0,0,1)\\) is \\(MA(1)\\).\n AR(p) An autoregressive (AR) model is a representation of a type of random process. The AR model specifies that the output variable depends linearly on its own previous values and on a stochastic term. In general, the AR model of order \\(p\\), i.e. \\(AR(p)\\), is defined as \\[y_t = c + \\sum_{i=1}^p \\phi_i y_{t-i} +\\epsilon_t,\\] where \\(\\phi_1,\\cdots,\\phi_p\\) are the parameters, \\(c\\) is a constant, and \\(\\epsilon_t\\) is white noise often assumed following \\(N(0,\\sigma^2)\\).\nFor AR(1), \\(|\\phi|\u0026lt;1\\) is necessary for the process to be stationary, such that \\[E(y_t) = E(y_{t-1}) = \\mu,\\] \\[\\text{var}(y_t) = \\text{var}(y_{t-1})=\\frac{\\sigma^2}{1-\\phi^2} = \\sigma_y^2,\\] assuming \\(y_{t}\\)’s and \\(\\epsilon_t\\)’s are independent from each other. The condition \\(|\\phi|\u0026lt;1\\) appears in the variance term so that \\(\\sigma_y^2\\) is finite and positive. Note that \\(\\text{var}(y_t)\\) in AR(1) is larger than in AR(0) i.e. regular linear models without autoregressions.\n I(d) Differencing in statistics is a transformation applied to time-series data in order to make it stationary. Differencing removes the changes in the level of a time series, eliminating trend and seasonality and consequently stabilizing the mean of the time series. The differenced data is then used for the estimation of an ARMA model.\nThe I(1) model of first-order differencing can be written as \\[D(y_t) = y_t - y_{t-1} = \\epsilon_t,\\] and the I(2) model of second-order differencing can be written as \\[D^2(y_t) = D(y_t) - D(y_{t-1}) = y_t - 2y_{t-1}+y_{t-2} = \\epsilon_t,\\] where \\(D()\\) is the operator of differencing and \\(D^d(y_t) = D^{d-1}(y_t) - D^{d-1}(y_{t-1})\\).\nAnother method of differencing data is seasonal differencing, which involves computing the difference between an observation and the corresponding observation in the previous period. For example, \\[y\u0026#39;_t = y_t - y_{t-s},\\] where \\(s\\) is the duration of season. We denote it as \\(D_s(y_t)\\).\n MA(q) The moving average model of order \\(q\\), i.e. \\(MA(q)\\), is given as \\[y_t = \\mu + \\epsilon_t + \\sum_{i=1}^q\\theta_i\\epsilon_{t-i},\\] where \\(\\theta_1,\\cdots,\\theta_q\\) are the parameters, \\(\\mu\\) is the expectation of \\(y_t\\), and \\(\\epsilon_t, \\epsilon_{t-1},\\cdots\\) are white noise error terms.\n ARIMA(p,d,q) Non-seasonal ARIMA Non-seasonal ARIMA models are generally denoted \\(ARIMA(p,d,q)\\) where parameters \\(p, d, q\\) are non-negative integers, \\(p\\) is the order (number of time lags) of the autoregressive model, \\(d\\) is the degree of differencing (the number of times the data have had past values subtracted), and \\(q\\) is the order of the moving-average model. In general, an \\(ARIMA(p,d, q)\\) model is given as \\[D^d(y_t) = \\delta + \\sum_{i=1}^p\\phi_i D^d(y_{t-i}) + \\epsilon_t + \\sum_{i=1}^q \\theta_i \\epsilon_{t-i},\\] where \\(D^d(y_t)\\) is the \\(d\\)-order difference of \\(y_t\\).\n Seasonal ARIMA Seasonal ARIMA models are usually denoted \\(ARIMA(p,d,q)\\times(P,D,Q)_s\\), where \\(s\\) refers to the time span of repeating seasonal pattern, and the uppercase \\(P,D,Q\\) refer to the autoregressive, differencing, and moving average terms for the seasonal part of the ARIMA model.\nThe non-seasonal components are the same as in non-seasonal ARIMA. As for the seasonal components, we have, for example,\n Seasonal AR: \\(y_t = c + \\sum_{i=1}^P\\psi_i y_{t-si}\\)\n Seasonal MA: \\(y_t = \\mu+ \\epsilon_t + \\sum_{i=1}^Q\\eta_i\\epsilon_{t-si}\\)\n Seasonal I: \\(D^D_s(y_t) = D^{D-1}_s(y_t)- D_s^{D-1}(y_{t-s})\\)\n   Examples Some well-known special cases arise naturally or are mathematically equivalent to other popular forecasting models. For example:\n An \\(ARIMA(0,1,0)\\) model (or \\(I(1)\\) model) is given by \\(X_{t}=X_{t-1}+\\epsilon_{t}\\), which is simply a random walk.\n An \\(ARIMA(0,1,0)\\) with a constant, given by \\(X_{t}=c+X_{t-1}+\\epsilon_{t}\\), which is a random walk with drift.\n An \\(ARIMA(0,0,0)\\) model is a white noise model.\n An \\(ARIMA(0,1,2)\\) model is a Damped Holt’s model.\n An \\(ARIMA(0,1,1)\\) model without constant is a basic exponential smoothing model.\n An \\(ARIMA(0,2,2)\\) model is given by \\(X_{t}=2X_{t-1}-X_{t-2}+(\\alpha +\\beta -2)\\epsilon_{t-1}+(1-\\alpha )\\epsilon_{t-2}+\\epsilon_{t}\\), which is equivalent to Holt’s linear method with additive errors, or second-order exponential smoothing.\n    ","date":1554249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554249600,"objectID":"7e7b00ad1b6edccfd3fadc69c929fdf4","permalink":"/post/2019-04-03-arima/","publishdate":"2019-04-03T00:00:00Z","relpermalink":"/post/2019-04-03-arima/","section":"post","summary":"Introduction The ARIMA (autoregressive integrated moving average) models are also known as Box–Jenkins models. ARIMA models are applied in some cases where data show evidence of non-stationarity, where an initial differencing step (corresponding to the “integrated” part of the model) can be applied one or more times to eliminate the non-stationarity.\nThe AR part of ARIMA indicates that the evolving variable of interest is regressed on its own lagged (i.","tags":["arima","time-series"],"title":"ARIMA","type":"post"},{"authors":null,"categories":["statistics"],"content":" Introduction State-space models were originally developed by control engineers, particularly for applications that require continuous updating of the current position. An example, from the field of navigation systems, is updating an user equipment’s position. The models have also found increasing use in many types of time-series problems, including parameter estimation, smoothing, and prediction. Structural time-series models are state-space models for time-series data. They are useful in practice because they are\n flexible : a very large class of models can be expressed in state space forms, including all ARIMA and VARMA models;\n modular : the model can be assembled from a library of state-component sub-models to capture important features of the data. Several widely used state components are available for capturing the trend, seasonality, or effects of holidays.\n  The bsts R package is a tool for fitting structural time series models using Bayesian methods and bsts stands for Bayesian structural time series. The bsts can be configured for short term or long term forecasting, incorporating one or more seasonal effects, or fitting explanatory models if forecasting is not the primary goal.\n General Form A general form of (univariate) structural time-series model can be written as \\[\\begin{split} \u0026amp; y_t = Z_t^T \\alpha_t + \\epsilon_t, \\qquad (\\text{observation equation})\\\\ \u0026amp; \\alpha_{t+1} = T_t\\alpha_{t} + R_t\\eta_t, \\qquad (\\text{transition or state equation})\\\\ \u0026amp; \\epsilon_t\\sim N(0,\\sigma^2_t),\\quad \\eta_t \\sim N(0, Q_t) \\end{split}\\] where \\(y_t\\) is the observed value of a time series at time \\(t\\), \\(\\alpha_t\\) is a \\(m\\)-dimensional state vector, \\(Z_t\\) is a \\(m\\)-dimensional output vector, \\(T_t\\) is a \\(m\\times m\\) transition matrix, \\(R_t\\) is a \\(m\\times q\\) control matrix, \\(\\epsilon_t\\) is a scalar observation error, and \\(\\eta_t\\) is a \\(q\\)-dimensional system error with a \\(q\\times q\\) state-diffusion matrix \\(Q_t\\) where \\(q\\leq m\\).\n The observation equation links the observed data \\(y_t\\) with the unobserved latent state \\(\\alpha_t\\).\n The state vector \\(\\alpha_t\\) is of prime importance and is usually unobserved or partially known. Although it may not be directly observable, it is often reasonable to assume that we know how it changes over time, and we denote the updating equation by the transition or state equation above. This equation defines how the latent space evolves over time.\n The arrays \\(Z_t, T_t, R_t\\) typically contain a mix of known values (often 0 and 1) and unknown parameters. The 0’s and 1’s indicate which bits of \\(\\alpha_t\\) are relevant for a particular computation.\n The \\(\\epsilon_t\\) and \\(\\eta_t\\) are generally assumed to be serially uncorrelated and also to be uncorrelated with each other at all time periods. In practice, we often assume \\(\\epsilon_t\\sim N(0,\\sigma_t^2)\\).\n The term \\(R_t\\eta_t\\) allows us to incorporate state components of less than full ranks. A model for seasonality will be the most important example.\n  The analyst chooses the structure of \\(\\alpha_t\\) based on the specific data and task, such as whether it is for short or long term forecast, whether the data contains seasonal effects, and whether and how regressors are to be included. Many of these models are standard, and can be fit using a variety of tools, such as the StructTS function distributed with base R or one of several R packages for fitting these models, such as the dlm package for dynamic linear model. The bsts package handles all the standard cases, but it also includes several useful extensions.\n State Components Static intercept We can add a static intercept term to a model, \\[y_t = c+\\epsilon_t,\\] where \\(c\\) is a constant value. If the structural time-series model includes a traditional trend component (e.g. local level, local linear trend, etc) then a separate intercept is not needed (and will probably cause trouble, as it will be confounded with the initial state of the trend model). However, if there is no trend, or the trend is an AR process centered around zero, then adding a static intercept will shift the center to a data-determined value.\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddStaticIntercept(ss, y)  Trend Local level The local level model assumes the trend is a random walk: \\[\\begin{split} \u0026amp;y_t = \\mu_t +\\epsilon_t,\\\\ \u0026amp;\\mu_{t+1} = \\mu_{t} + \\eta_{t} \\end{split}\\]\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddLocalLevel(ss, y)  AR An autoregressive (AR) model is a representation of a type of random process. The AR model specifies that the time series \\(y_t\\) depends linearly on its own previous values and on a stochastic term. In general, the AR model of order \\(p\\), i.e. \\(AR(p)\\), can be written as \\[\\begin{split} \u0026amp;y_t = \\mu_t +\\epsilon_t,\\\\ \u0026amp;\\mu_{t+1} = \\sum_{i=0}^{p-1} \\phi_i \\mu_{t-i} + \\eta_{t} \\end{split}\\] where \\(\\phi_0,\\cdots,\\phi_{p-1}\\) are the parameters of the model. # R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddAr(ss, y, lags = p) The bsts package also supports sparse AR(p) process for large \\(p\\), where a spike and slab prior is applied on the autoregression coefficients \\(\\phi_0,\\cdots, \\phi_{p-1}\\). This model differs from the one in AddAr() only in that some of its coefficients may be set to zero.\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddAutoAr(ss, y, lags = p)  Local linear trend The local linear trend is a popular choice for modelling trends because it quickly adapts to local variation, which is desirable when making short-term predictions. However, this degree of flexibility may not be desired when making long-term predictions, as such predictions often come with implausibly wide uncertainty intervals.\nA local linear trend model for \\(y_t\\) can be written as, \\[\\begin{split} \u0026amp; y_t = \\mu_t +\\epsilon_t, \\\\ \u0026amp; \\mu_{t+1} = \\mu_{t} + \\delta_t + \\eta_{\\mu,t}, \\qquad \\text{(stochastic level component)}\\\\ \u0026amp; \\delta_{t+1} = \\delta_t + \\eta_{\\delta,t}, \\qquad \\text{(stochastic slope component)}\\\\ \u0026amp; \\eta_{\\mu, t} \\sim N(0,\\sigma^2_{\\mu, t}),\\quad \\eta_{\\delta, t} \\sim N(0,\\sigma^2_{\\delta, t}) \\end{split}\\] where \\(\\mu_t\\) is the value of the trend at time \\(t\\), \\(\\delta_t\\) is the expected increase in \\(\\mu\\) between time \\(t\\) and \\(t+1\\) so it can be thought of as the slope at time \\(t\\), \\(\\eta_{\\mu,t}\\) and \\(\\eta_{\\delta, t}\\) are error terms independent from each other. A local linear trend allows both level (\\(\\mu_t\\)) and slope (\\(\\delta_t\\)) to be stochastic. It assumes that both the level and the slope follow random walks.\nThe model can also be expressed in the general form \\[\\begin{split} \u0026amp; y_t = [1\\quad 0]\\left[\\begin{matrix}\\mu_t\\\\\\delta_t\\end{matrix}\\right] +\\epsilon_t, \\\\ \u0026amp; \\left[\\begin{matrix}\\mu_{t+1}\\\\\\delta_{t+1}\\end{matrix}\\right] = \\left[\\begin{matrix}1 \u0026amp; 1\\\\ 0 \u0026amp; 1 \\end{matrix}\\right] \\left[\\begin{matrix}\\mu_t\\\\\\delta_t\\end{matrix}\\right] + \\left[\\begin{matrix}1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\end{matrix}\\right] \\left[\\begin{matrix}\\eta_{\\mu, t}\\\\\\eta_{\\delta, t}\\end{matrix}\\right], \\end{split}\\] where \\(Z_t = (1,0)^T\\), \\(\\alpha_t = (\\mu_t, \\delta_t)^T\\), \\(T_t = \\left[\\begin{smallmatrix}1 \u0026amp; 1\\\\ 0 \u0026amp; 1 \\end{smallmatrix}\\right]\\), \\(R_t=\\left[\\begin{smallmatrix}1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\end{smallmatrix}\\right]\\), and \\(\\eta_t = (\\eta_{\\mu,t}, \\eta_{\\delta, t})^T\\).\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddLocalLinearTrend(ss, y)  Semi-local linear trend The semi-local linear trend is similar to the local linear trend, but more useful for long-term forecasting. The model can be written as \\[\\begin{split} \u0026amp; y_t = \\mu_t +\\epsilon_t, \\\\ \u0026amp; \\mu_{t+1} = \\mu_{t} + \\delta_t + \\eta_{\\mu,t}, \\qquad \\text{(stochastic level component)}\\\\ \u0026amp; \\delta_{t+1} = a + \\phi\\times (\\delta_t-a) + \\eta_{\\delta,t}, \\qquad \\text{(stochastic slope component)}\\\\ \u0026amp; \\eta_{\\mu, t} \\sim N(0,\\sigma^2_{\\mu, t}),\\quad \\eta_{\\delta, t} \\sim N(0,\\sigma^2_{\\delta, t}) \\end{split}\\] where the slope component \\(\\delta_{t+1}\\) is modeled by an AR(1) process centered at value \\(a\\). A stationary AR(1) process is less variable than a random walk so it often gives more reasonable uncertainty estimates when making long term forecasts.\nThe model can be expressed in the general form with \\(Z_t = (1,0, a)^T\\), \\(\\alpha_t = (\\mu_t+a, \\delta_t-a, -1)^T\\), \\(T_t = \\left[\\begin{smallmatrix}1 \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; \\phi \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; 1 \\end{smallmatrix}\\right]\\), \\(R_t=\\left[\\begin{smallmatrix}1 \u0026amp; 0 \\\\ 0 \u0026amp; 1\\\\0\u0026amp;0 \\end{smallmatrix}\\right]\\), and \\(\\eta_t = (\\eta_{\\mu,t}, \\eta_{\\delta, t})^T\\).\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddSemilocalLinearTrend(ss, y)   Seasonality Regression with Seasonal Dummy Variables There are several commonly used state-component models to capture seasonality. The most frequently used model in the time domain is \\[\\begin{split} \u0026amp; y_t = \\gamma_t +\\epsilon_t, \\\\ \u0026amp; \\gamma_{t+d} = - \\sum_{i=0}^{s-2}\\gamma_{t-i\\times d} + \\eta_{\\gamma, t}, \\end{split}\\] where \\(s\\) is the number of seasons and \\(d\\) is the seasonal duration (number of time periods in each season, often set to 1). The model can be thought of as a regression on \\(s\\) dummy variables representing \\(s\\) seasons and \\(\\gamma_{t}\\) denotes their joint contribution to the observed response \\(y_t\\). The mean of \\(\\gamma_{t+d}\\) is such that the total seasonal effect is zero when summed over \\(s\\) seasons (i.e. \\(E(\\gamma_{t+d}+\\sum_{i=0}^{s-2}\\gamma_{t-i\\times d}) = 0\\)). The model can be rewritten as \\[\\begin{split} \u0026amp; y_t = [1\\quad 0 \\quad \\cdots\\quad 0]\\left[\\begin{matrix}\\gamma_{t}\\\\\\gamma_{t-d}\\\\ \\vdots\\\\ \\gamma_{t-(s-2)d}\\end{matrix}\\right] +\\epsilon_t, \\\\ \u0026amp; \\left[\\begin{matrix}\\gamma_{t+d}\\\\\\gamma_t\\\\\\gamma_{t-d}\\\\ \\vdots\\\\ \\gamma_{t-(s-4)d}\\\\ \\gamma_{t-(s-3)d}\\end{matrix}\\right] = \\left[\\begin{matrix} -1 \u0026amp; - 1 \u0026amp; \\cdots \u0026amp; -1 \u0026amp; -1 \\\\ 1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp;0\u0026amp; 0\\\\ 0 \u0026amp; 1 \u0026amp; \\cdots \u0026amp; 0 \u0026amp;0 \\\\ \\vdots \u0026amp;\\vdots \u0026amp;\\vdots \u0026amp;\\vdots \u0026amp;\\vdots \u0026amp;\\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 1 \u0026amp; 0 \\\\ 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; 0 \\\\ \\end{matrix}\\right] \\left[\\begin{matrix}\\gamma_{t}\\\\\\gamma_{t-d}\\\\\\gamma_{t-2d}\\\\\\vdots \\\\ \\gamma_{t-(s-3)d}\\\\ \\gamma_{t-(s-2)d}\\end{matrix}\\right] + \\left[\\begin{matrix}1\\\\0\\\\0\\\\ \\vdots\\\\ 0\\\\ 0\\end{matrix}\\right]\\eta_{\\gamma, t} \\end{split}\\]\nThe seasonal model can be generalized to allow for multiple seasonal components with different periods.\n# R code # Suppose that y is a time series collected hourly ss \u0026lt;- list() # daily seasonality ss \u0026lt;- bsts::AddSeasonal(ss, y, nseasons = 24, season.duration = 1) # weely seasonality ss \u0026lt;- bsts::AddSeasonal(ss, y, nseasons = 7, season.duration = 24)  Trigonometric Seasonal model Another way to model seasonality is to use trigonometric seasonal model, \\[\\begin{split} \u0026amp; y_t = \\gamma_t +\\epsilon_t, \\\\ \u0026amp; \\gamma_{j, t+1} = \\gamma_{j,t}\\times \\cos(\\lambda_j) - \\gamma^*_{j,t}\\times \\sin(\\lambda_j) + \\omega_{j, t},\\\\ \u0026amp; \\gamma^*_{j, t+1} = \\gamma^*_{j,t}\\times \\cos(\\lambda_j) - \\gamma_{j,t}\\times \\sin(\\lambda_j) + \\omega^*_{j,t},\\\\ \\end{split}\\] where \\(\\gamma_t = \\sum_{j=1}^{k}\\gamma_{j,t}\\), \\(\\lambda_j = 2\\pi j/s\\) is the \\(j\\)-th seasonal frequency, \\(j = 1,\\cdots, k\\), and \\(s\\) is the number of time steps required for the longest cycle to repeat (i.e. number of seasosns).\n# R code ss \u0026lt;- list() # The harmonic method is strongly preferred to the direct method. # For a time series collected hourly with daily # seasonality, we can try # the component below, where frequencies = 1:4 specifies the frequencis of sin, cos functions we will use. ss \u0026lt;- bsts::AddTrig(ss, y, period = 24, frequencies = 1:4, method = \u0026quot;harmonic\u0026quot;)   Linear regression The covariates in structural time series models are assumed to be contemporaneous. The coefficients of the contemporaneous covariates \\(\\mathbf{x}_t\\) can be static or time-varying.\nA static regression can be written in state-space form by setting \\(Z_t = \\beta^T \\mathbf{x}_t\\) and \\(\\alpha_t =1\\), where \\(\\beta\\) is static.\n# R code ss \u0026lt;- list() bsts::bsts(y ~ x, ss, niter = 500) A dynamic regression component can be written as \\[\\begin{split} \u0026amp; \\mathbf{x}_t^T\\beta_t = \\sum_{j=1}^J x_{j,t} \\beta_{j,t}\\\\ \u0026amp; \\beta_{j, t+1} = \\beta_{j,t} + \\eta_{\\beta,j,t}, \\end{split}\\] where \\(\\beta_{j,t}\\) is the coefficient for the \\(j\\)-th covariate \\(x_{j,t}\\) at time \\(t\\). The state-space form is given as \\(Z_t = \\mathbf{x}_t, \\alpha_t =\\beta_t, T_t = R_t = I_{J\\times J}\\).\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddDynamicRegression(ss, y ~ x) bsts::bsts(y, ss, niter = 500)  Assemble multiple state components Independent state components can be combined by concatenating their observation vectors \\(Z_t\\) and arranging the other model matrices as elements in a block diagonal matrix. For example, we can combine the local linear trend with seasonality and have the following model matrices: \\[Z_t = \\left[\\begin{smallmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\vdots\\\\ 0\\end{smallmatrix}\\right], T_t = \\left[\\begin{smallmatrix} 1 \u0026amp; 1 \u0026amp; \\\\ 0 \u0026amp; 1 \u0026amp; \\\\ \u0026amp; \u0026amp; -1 \u0026amp; - 1 \u0026amp; \\cdots \u0026amp; -1 \u0026amp; -1 \\\\ \u0026amp; \u0026amp; 1 \u0026amp; 0 \u0026amp; \\cdots \u0026amp;0\u0026amp; 0\\\\ \u0026amp; \u0026amp; 0 \u0026amp; 1 \u0026amp; \\cdots \u0026amp; 0 \u0026amp;0 \\\\ \u0026amp; \u0026amp; \\vdots \u0026amp;\\vdots \u0026amp;\\vdots \u0026amp;\\vdots \u0026amp;\\vdots \u0026amp;\\\\ \u0026amp; \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 1 \u0026amp; 0 \\\\ \u0026amp; \u0026amp; 0 \u0026amp; 0 \u0026amp; \\cdots \u0026amp; 0 \u0026amp; 0 \\\\ \\end{smallmatrix}\\right], R_t=\\left[\\begin{smallmatrix} 1 \u0026amp; 0 \\\\ 0 \u0026amp; 1 \\\\ \u0026amp; \u0026amp; 1 \\\\ \u0026amp; \u0026amp; 0 \\\\ \u0026amp; \u0026amp; \\vdots \\\\ \u0026amp; \u0026amp; 0 \\\\ \\end{smallmatrix}\\right] \\]\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddLocalLinearTrend(ss, y) ss \u0026lt;- bsts::AddSeasonality(ss, y, nseason = s, season.duration = d) bsts::bsts(y, ss, niter = 500) Similarly, we can add other state components such as Regression, Local level, AR process, Random walk for holiday effect, etc (see bsts Package for more details). As mentioned in the Introduction, the model is modular and can be easily extended by using the bsts package. For example,\n# R code ss \u0026lt;- list() ss \u0026lt;- bsts::AddLocalLevel(ss, y) ss \u0026lt;- bsts::AddAr(ss, y) ss \u0026lt;- bsts::AddSeasonal(ss, y, nseasons = 24) ss \u0026lt;- bsts::AddDynamicRegression(ss, y ~ x1) bsts::bsts(y ~ x2, ss, niter = 500) Some examples of application to real data analyses can be found here.\n  Model diagnostic Prediction errors As part of the model fitting process, the algorithm in bsts generates the one-step-ahead prediction errors \\(y_tb\u0008\u0012E(y_t|Y_{tb\u0008\u00121},\\theta)\\) , where \\(Y_{tb\u0008\u00121}=y_1,\\cdots,y_{tb\u0008\u00121}\\), and the vector of model parameters \\(\\theta\\) is fixed at its current value in the MCMC algorithm. The one-step-ahead prediction errors can be obtained from the bsts model by calling\nbsts.prediction.errors(model1) The one step prediction errors are a useful diagnostic for comparing several bsts models that have been fit to the same data. They are used to implement the function CompareBstsModels, which is called as shown below.\nCompareBstsModels(list(\u0026quot;Model 1\u0026quot; = model1, \u0026quot;Model 2\u0026quot; = model2, \u0026quot;Model 3\u0026quot; = model3), colors = c(\u0026quot;black\u0026quot;, \u0026quot;red\u0026quot;, \u0026quot;blue\u0026quot;))  Model assumptions In BSTS models, the residual term is often assumed to follow a Gaussian distribution. It is important to check the validity of such assumption to see if the model is valid or not.\nThe output of bsts model contains a matrix of Monte Carlo draws of residual errors. Each row is a Monte Carlo draw, and each column is an observation.\nThe qqdist function sorts the columns of draws by their mean, and plots the resulting set of curves against the quantiles of the standard normal distribution. A reference line is added, and the mean of each column of draws is represented by a blue dot. If the dots fall around the straight line, the normality assumption holds well for the residuals. If the dots depart greatly from the line, the normality assumption may violate. In this case, we may either do data transformation to obtain more normally distributed data or assume a different distribution on the data (e.g. t-distribution)\nThe AcfDist function plots the posterior distribution of the autocorrelation function (ACF) of the residuals using a set of side-by-side boxplots. If the boxplot of lag \\(k\\) contains 0, we may consider the residuals are uncorrelated at lag \\(k\\). If the ACF does not dampen out (i.e. falling to zero) within about 15 to 20 lags, the residual term is nonstationary and we should try a different model.\n  References Steven L. Scott. (2017). Fitting Bayesian structural time series with the bsts R package. http://www.unofficialgoogledatascience.com/2017/07/fitting-bayesian-structural-time-series.html.\nChatfield, Chris. (2016). The analysis of time series: an introduction. CRC press.\nMontgomery, Douglas C., Cheryl L. Jennings, and Murat Kulahci. (2015). Introduction to time series analysis and forecasting. John Wiley \u0026amp; Sons.\n ","date":1553126400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553126400,"objectID":"5a43568427900f38d6e1a6d76c89c1f3","permalink":"/post/2019-03-21-bsts/","publishdate":"2019-03-21T00:00:00Z","relpermalink":"/post/2019-03-21-bsts/","section":"post","summary":"Introduction State-space models were originally developed by control engineers, particularly for applications that require continuous updating of the current position. An example, from the field of navigation systems, is updating an user equipment’s position. The models have also found increasing use in many types of time-series problems, including parameter estimation, smoothing, and prediction. Structural time-series models are state-space models for time-series data. They are useful in practice because they are","tags":["bsts","time-series"],"title":"Structural Time-Series Models","type":"post"},{"authors":null,"categories":null,"content":" SQL notes       code{white-space: pre;} pre:not([class]) { background-color: white; }  if (window.hljs) { hljs.configure({languages: []}); hljs.initHighlightingOnLoad(); if (document.readyState \u0026\u0026 document.readyState === \"complete\") { window.setTimeout(function() { hljs.initHighlighting(); }, 0); } }  h1 { font-size: 34px; } h1.title { font-size: 38px; } h2 { font-size: 30px; } h3 { font-size: 24px; } h4 { font-size: 18px; } h5 { font-size: 16px; } h6 { font-size: 12px; } .table th:not([align]) { text-align: left; }  .main-container { max-width: 940px; margin-left: auto; margin-right: auto; } code { color: inherit; background-color: rgba(0, 0, 0, 0.04); } img { max-width:100%; height: auto; } .tabbed-pane { padding-top: 12px; } .html-widget { margin-bottom: 20px; } button.code-folding-btn:focus { outline: none; } summary { display: list-item; }  .tabset-dropdown  .nav-tabs { display: inline-table; max-height: 500px; min-height: 44px; overflow-y: auto; background: white; border: 1px solid #ddd; border-radius: 4px; } .tabset-dropdown  .nav-tabs  li.active:before { content: \"\"; font-family: 'Glyphicons Halflings'; display: inline-block; padding: 10px; border-right: 1px solid #ddd; } .tabset-dropdown  .nav-tabs.nav-tabs-open  li.active:before { content: \"\"; border: none; } .tabset-dropdown  .nav-tabs.nav-tabs-open:before { content: \"\"; font-family: 'Glyphicons Halflings'; display: inline-block; padding: 10px; border-right: 1px solid #ddd; } .tabset-dropdown  .nav-tabs  li.active { display: block; } .tabset-dropdown  .nav-tabs  li  a, .tabset-dropdown  .nav-tabs  li  a:focus, .tabset-dropdown  .nav-tabs  li  a:hover { border: none; display: inline-block; border-radius: 4px; } .tabset-dropdown  .nav-tabs.nav-tabs-open  li { display: block; float: none; } .tabset-dropdown  .nav-tabs  li { display: none; }   $(document).ready(function () { window.buildTabsets(\"TOC\"); }); $(document).ready(function () { $('.tabset-dropdown  .nav-tabs  li').click(function () { $(this).parent().toggleClass('nav-tabs-open') }); });    SQL notes Tingting Yu 2019-07-14  Introduction Structured Query Language (SQL) is a standard computer language for relational database management and data manipulation. It can be used to read, write, and update data. For data scientists, it is mainly used for data retrieval. There are several relational database management systems, such as Oracle, MySQL, and SQLite. Depending on the system you are using, the SQL syntax may be a little bit different.\n Retrieve data Use SELECT statement to query database, filtered by some conditions (optional). The [ ] is used to state optional clauses. To select all columns, use * after the SELECT keyword.\nSELECT \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt; FROM \u0026lt;tablename\u0026gt; [WHERE \u0026lt;condition\u0026gt;]; Conditional selections used in the WHERE clause:\n= Equal \u0026lt;\u0026gt; Not equal to \u0026gt; Greater than \u0026lt; Less than \u0026gt;= Greater than or equal \u0026lt;= Less than or equal BETWEEN AND Within a range IS NULL Is a null LIKE Pattern matching operator IN (\u0026lt;val1\u0026gt;, \u0026lt;val2\u0026gt;, ...) OR AND NOT  Sometimes IN and OR can accomplish the same thing. But in general, IN executes faster than OR and it allows to use another SELECT for subqueries.\n SQL processes AND before OR. Use ( ) when using AND and OR together to avoid confusion in the order of operations.\n  Wildcards for pattern matching:\n Using % for pattern matching: ‘%a’, end with a; ‘a%’, start with a; ‘%a%’, with a in between; ‘a%z’, start with a and end with z; ‘a%@gmail.com’, grab gmail addresses start with a.\n Using underscore _ for matching a single character: ‘_day’, grab four-letter words that end with ‘day’.\n Wildcards take longer to run than regular operators. Avoid using them if they can be replaced by other operators.\n  Example\nThe code below select two columns from a table named nameInfo and only select rows where the lastname ends in “son”.\nSELECT firstname, lastname FROM nameInfo WHERE lastname LIKE '%son';  Create table Use CREATE TABLE statement to create a new table, with optional constraints associated with each column respectively. The table and column names must start with a letter and can be followed by letters, numbers, or underscores The maximum length of a name is 30 characters.\nCREATE TABLE \u0026lt;tablename\u0026gt; (\u0026lt;column1\u0026gt; \u0026lt;data type\u0026gt; [constraint], \u0026lt;column2\u0026gt; \u0026lt;data type\u0026gt; [constraint] ); Use CREATE TEMPORARY TABLE statement to create a temporary table. It is faster to create a temporary table than a real table. However, temporary tables will be deleted when current session is terminated.\nCREATE TEMPORARY TABLE \u0026lt;temp_tablename\u0026gt; AS ( SELECT * FROM \u0026lt;tablename\u0026gt; [WHERE \u0026lt;conditions\u0026gt;] ) Common data types in SQL\nchar(size) Character string with a fixed length. Varchar(size) Character string with a maximum number of length. date Date value number(size) Number value with a maximum number of integer digits. number(size, d) Number value with a maximum number of \u0026quot;size\u0026quot; integer digits and a maximum number of \u0026quot;d\u0026quot; fraction digits. decimal(n, d) Common constraints\nUNIQUE No two records can have the same value in a particular column. NOT NULL A column can't be left blank. PRIMARY KEY Defines a unique identification of each record (or row) in a table. Cannot contain NULL. Example\nCREATE TABLE nameInfo (idnumber number(12) UNIQUE, firstname Varchar(20), lastname Varchar(20), age number(3), country Varchar(10) );  Insert and delete rows Use INSERT INTO statement to insert rows into a table. All strings should be enclosed in single quotes, for example ‘September’.\nINSERT INTO \u0026lt;tablename\u0026gt; (col_1, ... , col_n) VALUES (value_1, ..., value_n); Use DELETE FROM statement to delete rows from a table.\nDELETE FROM \u0026lt;tablename\u0026gt; WHERE \u0026lt;col_1\u0026gt; OPERATOR \u0026lt;value_1\u0026gt; [AND|OR \u0026lt;col_2\u0026gt; OPERATOR \u0026lt;value_2\u0026gt;]; Examples\nINSERT INTO nameInfo (idnumber, firstname, lastname, age, country) VALUES (1234567, 'John', 'Lee', 45, 'Canada'); DELETE FROM nameInfo WHERE lastname = 'May';  Insert column Add column to a table in a database:\nAFTER TABLE \u0026lt;tablename\u0026gt; ADD \u0026lt;columnname\u0026gt; \u0026lt;datatype\u0026gt;; SELECT \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt;, \u0026lt;col1\u0026gt; + \u0026lt;col2\u0026gt; AS \u0026lt;col3\u0026gt;  Update records Use UPDATE statement to update records that match a specified criteria.\nUPDATE \u0026lt;tablename\u0026gt; SET \u0026lt;columnname\u0026gt; = \u0026lt;newvalue\u0026gt; [, \u0026lt;nextcolumn\u0026gt; = \u0026lt;newvalue2\u0026gt;, ... ] WHERE \u0026lt;columnname\u0026gt; OPERATOR \u0026lt;value\u0026gt; [AND|OR \u0026lt;column\u0026gt; OPERATOR \u0026lt;value\u0026gt;]; Example\nUPDATE nameInfo SET lastname = 'Li', age = 48, WHERE lastname = 'Lee' AND firstname = 'John';  Drop a table Use DROP TABLE command to delete a table and all rows in the table. It is different from deleting all the records in the table. The former removes the table definition as well as all of its rows and the latter leaves the table including column and constraint information.\nDROP TABLE \u0026lt;tablename\u0026gt;  Sort a table Use ORDER BY statement to sort a table. It must be the last clause in a select statement.\nSELECT \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt; FROM \u0026lt;tablename\u0026gt; ORDER BY \u0026lt;col1\u0026gt; DESC, \u0026lt;col2\u0026gt; ASC, \u0026lt;col3\u0026gt; ASC; You can sort by a column not retrieved and use DESC or ASC for descending or ascending (default) order.\n Aggregate functions AVG() COUNT() MIN() MAX() SUM()   Rows containing NULL values are ignored by AVG(), MIN(), MAX().\n COUNT(*): count all the rows containing values or NULL;\n COUNT(\u0026lt;colname\u0026gt;): count all the rows in a specific column ignoring NULL values;\n Use DISTINCT on aggregate functions. For example, COUNT( DISTINCT \u0026lt;colname\u0026gt;).\n  Examples\nSELECT AVG(score) AS average_score  Group data Use GROUP BY clause to group data and use HAVING clause for filtering for groups. They are used after WHERE clause and hence rows filtered out by WHERE will not be included in GROUP BY clause.\nSELECT \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt;, [some aggregated calculations] FROM \u0026lt;tablename\u0026gt; GROUP BY \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt; [HAVING \u0026lt;condition\u0026gt;];  Every column in your SELECT statement must be present in a GROUP BY clause, except for aggregated calculations.\nExample\nSELECT customerID, COUNT(*) AS orders FROM Orders GROUP BY customerID HAVING COUNT(*) \u0026gt;= 2 ;   Using subqueries Subqueries are queries embedded into other queries. Since data is often stored in multiple tables, subqueries are useful when it comes to getting information from multiple tables. Moreover, they are often used for adding additional criteria, such as filtering criteria, from another table into your query. Subquery selects can only retrieve a single column.\nThere is no limit to the number of subqueries you can have. But the performance in obtaining the results slows down when the subqueries are deeply nested.\nExample\nSELECT studentID, firstname, lastname, major FROM studentList WHERE studentiID IN ( SELECT studentID FROM gradeList WHERE score \u0026gt; 80 );  Joining tables A join allows you to retrieve the data from multiple tables in just one query. The result only exists for the duration of the query execution.\nCartesian (cross) joins A Cartesian join allows you to take each record from the first table and match it with all of the records from the second table. If the first table contains x rows and second table contains y rows, you will have x*y rows in the end result. It is computationally taxing and is not matching on anything. So it is not frequently used.\nSELECT \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt;, \u0026lt;col3\u0026gt; FROM \u0026lt;table1\u0026gt; CROSS JOIN \u0026lt;table2\u0026gt;;  Inner joins An inner join is used to select records that have matching values in both tables on some keys.\nSELECT \u0026lt;col1\u0026gt;, \u0026lt;col2\u0026gt;, \u0026lt;col3\u0026gt; FROM \u0026lt;table1\u0026gt; INNER JOIN \u0026lt;table2\u0026gt; ON \u0026lt;prequalified key1\u0026gt; = \u0026lt;prequalified key2\u0026gt; ; Example\nSELECT studentID, firstname, lastname, score FROM studentList INNER JOIN gradeList ON studentList.studentID = gradeList.studentID;  Aliases and self joins An alias is helpful because it can help you by just shortening names and simplifying how we are pre-qualifying them. It doesn’t rewrite anything of the table permanently and is only stored for the duration of the query.\nExample\nSELECT studentID, firstname, lastname FROM studentList AS stud, gradeList AS grade WHERE stud.studentID = grade.studentID ; A self join takes the table and treat it like two separate tables. The following example matches customers that are from the same city.\nExample\nSELECT A.name AS name1, B.name AS name2, A.city FROM Customers A, Customers B WHERE A.customerID = B.customberID AND A.city = B.city ORDER BY A.city;  Left, right, full outer joins The left join returns all the records from the table on the left side and the matched records from the right table. The following example selects all customers and any orders they might have:\nSELECT C.name, O.orderID FROM Customers C LEFT JOIN Orders O ON C.customerID = O.customerID ORDER BY C.name The difference between the right and left joins is the order the tables are relating. Right joins can be turned into left joins by reversing the order of the tables.\nThe full outer join returns all records when there is a match in either left or right table. The following example selects all customers and all orders.\nSELECT C.name, O.orderID FROM Customers C FULL OUTER JOIN Orders O ON C.customerID = O.customerID ORDER BY C.name ;  Unions The UNION is used to combine the result set of two or more SELECT statements. Each SELECT statement within UNION must have the same number of columns and the columns must be in the same order with similar data types.\nSELECT \u0026lt;colnames\u0026gt; FROM \u0026lt;table1\u0026gt; UNION SELECT \u0026lt;colnames\u0026gt; FROM \u0026lt;table2\u0026gt; The following example selects the German cities that have suppliers.\nSELECT city, country FROM Customers WHERE country = 'germany' UNION SELECT city, country FROM supplier WHERE country = 'germany' ORDER BY city;   Working with text strings Concatenations Use || to concatenate strings. SQL server supports + instead of ||.\nSELECT CompanyName, ContactName, CompanyName || '(' || ContactName || ')' FROM customers  Trimming Use LTRIM, RTRIM, TRIM to trim the leading, trailing, or both space from a string.\nSELECT TRIM(\u0026quot; Hello. \u0026quot;) AS TrimmedString  Substring Use SUBSTR to return the specified number of characters from a particular position of a given string.\nSELECT firstname, SUBSTR (firstname, 2, 4) # pull 4 characters, starting at the 2nd character FROM employees  Upper and lower SELECT UPPER(firstname) FROM employees; SELECT LOWER(firstname) FROM employees;   Working with date and time strings SQLite supports 5 date and time functions:\nDATE(timestring, modifier, modifier, ...) TIME(timestring, modifier, modifier, ...) DATETIME(timestring, modifier, modifier, ...) JULIANDAY(timestring, modifier, modifier, ...) # Extract certain parts of a date or time string. # format components: %Y %m %d %H %M %S %s STRFTIME(format, timestring, modifier, modifier, ...) A timestring can be in any of the following formats\nYYYY-MM-DD YYYY-MM-DD HH:MM YYYY-MM-DD HH:MM:SS YYYY-MM-DD HH:MM:SS.SSS YYYY-MM-DDTHH:MM YYYY-MM-DDTHH:MM:SS YYYY-MM-DDTHH:MM:SS.SSS HH:MM HH:MM:SS HH:MM:SS.SSS Examples\nSELECT DATE('now') # compute current date SELECT STRFTIME('%Y %m %d', 'now') SELECT Birthdate, STRFTIME('%Y', Birthdate) AS Year, STRFTIME('%m', Birthdate) AS Month, STRFTIME('%d', Birthdate) AS Day, DATE(('now') - Birthdate) AS Age FROM employees  Case statements A case statement mimics if-else statement found in most programming languages. It can be used in SELECT, INSERT, UPDATE, and DELETE statements.\nCASE [input_var_name] WHEN C1 THEN E1 WHEN C2 THEN E2 ... [ELSE else_result] END new_var_name Example\nSELECT studentid, firstname, lastname, score, CASE WHEN score \u0026gt;= 60 THEN 'pass' WHEN score \u0026lt; 60 THEN 'fail' ELSE 'other' END score_category FROM exam_result  Views A view is essentially a stored query. It will be removed after database connect has ended.\nBenefits:\n It can add or remove columns without changing the schema.\n It provides a simpler option to creating a new table.\n It helps us clean up our queries and simplify the queries when we have to write\n It can be used to encapsulate complex queries or calculations that you are trying to write.\n  CREATE [TEMP] VIEW [IF NOT EXISTS] view_name AS SELECT \u0026lt;list of column names\u0026gt; FROM datatable # To see the view SELECT * FROM view_name # Remove the view DROP VIEW view_name    // add bootstrap table styles to pandoc tables function bootstrapStylePandocTables() { $('tr.header').parent('thead').parent('table').addClass('table table-condensed'); } $(document).ready(function () { bootstrapStylePandocTables(); });   (function () { var script = document.createElement(\"script\"); script.type = \"text/javascript\"; script.src = \"https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"; document.getElementsByTagName(\"head\")[0].appendChild(script); })();    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c6b8d41fce3c26e0aba336acb2d2cf8e","permalink":"/post/2019-07-14-sql/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/2019-07-14-sql/","section":"post","summary":"SQL notes       code{white-space: pre;} pre:not([class]) { background-color: white; }  if (window.hljs) { hljs.configure({languages: []}); hljs.initHighlightingOnLoad(); if (document.readyState \u0026\u0026 document.readyState === \"complete\") { window.setTimeout(function() { hljs.initHighlighting(); }, 0); } }  h1 { font-size: 34px; } h1.title { font-size: 38px; } h2 { font-size: 30px; } h3 { font-size: 24px; } h4 { font-size: 18px; } h5 { font-size: 16px; } h6 { font-size: 12px; } .","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c8bc6f47bdfa5be820b3e153b7d892f5","permalink":"/publication/publications/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/publications/","section":"publication","summary":"","tags":null,"title":"","type":"publication"}]